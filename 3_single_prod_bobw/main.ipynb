{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b2b64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS AND DEPENDENCIES\n",
    "# =============================================================================\n",
    "\n",
    "import numpy as np                    # Numerical computations and arrays\n",
    "import random                        # Random number generation\n",
    "import matplotlib.pyplot as plt      # Plotting and visualization\n",
    "import scipy.stats as stats          # Statistical distributions and functions\n",
    "from scipy import optimize          # Optimization algorithms\n",
    "from collections import Counter     # For counting frequency distributions\n",
    "\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "from Hedge import HedgeAgent1D\n",
    "from EXP3_P import Exp3Agent\n",
    "\n",
    "from Primal_Dual import PrimalDualAgent\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b331bc84",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb0baf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ENVIRONMENT: NON-STATIONARY STOCHASTIC PRICING\n",
    "# =============================================================================\n",
    "\n",
    "class NonStationaryStochasticPricingEnvironment:\n",
    "    \"\"\"\n",
    "    Non-stationary stochastic environment for dynamic pricing problems.\n",
    "    \n",
    "    Customer valuations follow time-varying distributions that change every round,\n",
    "    creating a challenging online learning scenario where the agent must adapt\n",
    "    to shifting customer preferences while managing inventory constraints.\n",
    "    \n",
    "    Key Features:\n",
    "    - Non-stationary customer valuations (distributions change over time)\n",
    "    - Stochastic demand with configurable noise\n",
    "    - Supports discrete price sets\n",
    "    - Tracks round progression automatically\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, valuation_distributions, prices, demand_noise_std=0.03):\n",
    "        \"\"\"\n",
    "        Initialize the non-stationary pricing environment.\n",
    "        \n",
    "        Args:\n",
    "            valuation_distributions: List of scipy.stats distributions representing \n",
    "                                   customer valuations for each round\n",
    "            prices: Array of available discrete price options\n",
    "            demand_noise_std: Standard deviation of noise in demand probability (default: 0.03)\n",
    "        \"\"\"\n",
    "        self.valuation_dist = valuation_distributions\n",
    "        self.noise_std = demand_noise_std\n",
    "        self.current_round = 0\n",
    "        self.prices = prices\n",
    "\n",
    "    def demand_probability(self, price):\n",
    "        \"\"\"\n",
    "        Calculate the probability that a customer purchases at the given price.\n",
    "        \n",
    "        The probability is computed as P(customer_valuation >= price) plus noise.\n",
    "        This represents customers buying when their willingness-to-pay exceeds price.\n",
    "        \n",
    "        Args:\n",
    "            price: The price at which to evaluate demand probability\n",
    "            \n",
    "        Returns:\n",
    "            float: Purchase probability in [0, 1]\n",
    "        \"\"\"\n",
    "        # Get current round's valuation distribution\n",
    "        current_dist = self.valuation_dist[self.current_round]\n",
    "\n",
    "        # Base probability: P(valuation >= price)\n",
    "        base_prob = 1 - current_dist.cdf(price)\n",
    "        \n",
    "        # Add stochastic noise to create realistic demand uncertainty\n",
    "        noise = np.random.normal(0, self.noise_std)\n",
    "        \n",
    "        # Ensure probability remains in valid range [0, 1]\n",
    "        prob = np.clip(base_prob + noise, 0, 1)\n",
    "        return prob\n",
    "\n",
    "    def simulate_round(self, price):\n",
    "        \"\"\"\n",
    "        Simulate one pricing round with a customer interaction.\n",
    "        \n",
    "        This method:\n",
    "        1. Draws a random customer valuation from current round's distribution\n",
    "        2. Determines if customer purchases (valuation >= price)\n",
    "        3. Calculates revenue from the interaction\n",
    "        4. Computes counterfactual outcomes for all possible prices\n",
    "        5. Advances to next round\n",
    "        \n",
    "        Args:\n",
    "            price: The price offered to the customer\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (sale_made, revenue, sale_made_full, revenue_full, valuation)\n",
    "                - sale_made: Binary indicator if sale occurred\n",
    "                - revenue: Revenue from this transaction\n",
    "                - sale_made_full: Array of sale indicators for all prices\n",
    "                - revenue_full: Array of revenues for all prices\n",
    "                - valuation: The actual customer valuation sampled\n",
    "        \"\"\"\n",
    "        # Get current round's valuation distribution\n",
    "        current_dist = self.valuation_dist[self.current_round]\n",
    "\n",
    "        # Sample customer valuation from current distribution\n",
    "        valuation = current_dist.rvs()\n",
    "        \n",
    "        # Customer purchases if their valuation >= offered price\n",
    "        sale_made = 1 if valuation >= price else 0\n",
    "        \n",
    "        # Revenue is price if sale was made, 0 otherwise\n",
    "        revenue = sale_made * price\n",
    "        \n",
    "        # Compute counterfactual outcomes for all possible prices\n",
    "        # This helps the agent understand what would have happened\n",
    "        sale_made_full = (valuation >= self.prices).astype(int)\n",
    "        revenue_full = self.prices * sale_made_full\n",
    "        \n",
    "        # Advance to next round (important for non-stationarity)\n",
    "        self.current_round += 1\n",
    "\n",
    "        return sale_made, revenue, sale_made_full, revenue_full, valuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa861eb",
   "metadata": {},
   "source": [
    "# Environment Configuration Notes\n",
    "\n",
    "The environment uses different probability distributions for each round to create a non-stationary setting where customer valuations change over time. This creates a challenging online learning scenario.\n",
    "\n",
    "When defining the environment configuration, a lambda function is used for the mean and standard deviation. A vector of distributions is created to be passed to the environment. It may even make sense to change the distribution (and not just make them normal), to create a sharper change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d676aad",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8596f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SIMULATION RUNNER: PRIMAL-DUAL PRICING EXPERIMENT\n",
    "# =============================================================================\n",
    "\n",
    "def run_simulator(T, valuation_dist, agent_params, n_simulations=1, verbose=True):\n",
    "    \"\"\"\n",
    "    Run the Primal-Dual pricing simulation with comprehensive tracking.\n",
    "    \n",
    "    This function orchestrates the interaction between the non-stationary environment\n",
    "    and the primal-dual agent over T rounds, tracking all relevant metrics for\n",
    "    performance analysis and regret calculation.\n",
    "    \n",
    "    Args:\n",
    "        T: Number of rounds to simulate\n",
    "        valuation_dist: List of customer valuation distributions (one per round)\n",
    "        agent_params: Agent initialization parameters\n",
    "        n_simulations: Number of independent simulation runs (default: 1)\n",
    "        verbose: Whether to print progress and statistics\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing:\n",
    "            - selected_prices: List of prices chosen by agent each round\n",
    "            - revenues: List of revenues earned each round\n",
    "            - sales: List of binary sale indicators each round\n",
    "            - cumulative_revenue: List of cumulative revenue over time\n",
    "            - best_price: Best performing price according to agent\n",
    "            - best_reward: Maximum cumulative reward achieved\n",
    "            - first_inventory_empty: Round when inventory first depleted (if any)\n",
    "            - total_revenue: Final total revenue\n",
    "            - agent: Trained agent instance for analysis\n",
    "            - actual_valuations: List of actual customer valuations observed\n",
    "    \"\"\"\n",
    "    # Initialize result containers\n",
    "    selected_prices = []\n",
    "    revenues = []\n",
    "    sales = []\n",
    "    cumulative_revenue = []\n",
    "    total_revenue = 0\n",
    "    best_price = []\n",
    "    best_reward = []\n",
    "    first_inventory_empty = None\n",
    "    actual_valuations = []  # Track actual customer valuations\n",
    "\n",
    "    for sim in range(n_simulations):\n",
    "        if verbose:\n",
    "            print(f\"\\n=== Running Primal-Dual Pricing Simulation #{sim + 1} ===\")\n",
    "            print(f\"Time horizon: {T:,} rounds\")\n",
    "            print(f\"Inventory constraint: {agent_params['P']:,} units\")\n",
    "            print(f\"Non-stationary environment: {len(valuation_dist):,} distributions\")\n",
    "\n",
    "        # Initialize environment and agent\n",
    "        env = NonStationaryStochasticPricingEnvironment(\n",
    "            valuation_distributions=valuation_dist,\n",
    "            prices=agent_params['prices']\n",
    "        )\n",
    "        agent = PrimalDualAgent(**agent_params)\n",
    "\n",
    "        # Main simulation loop\n",
    "        for t in range(T):\n",
    "            # Track inventory depletion\n",
    "            if agent.remaining_inventory < 1 and first_inventory_empty is None:\n",
    "                first_inventory_empty = t\n",
    "                if verbose and t % 1000 == 0:\n",
    "                    print(f\"Inventory empty for the first time at round {t}\")\n",
    "\n",
    "            # Agent selects price based on current state\n",
    "            price = agent.bid()\n",
    "            price_idx = agent.bid_index\n",
    "\n",
    "            # Simulate customer interaction in environment\n",
    "            if agent.remaining_inventory <= 0:\n",
    "                # No inventory: force no sale and zero revenue\n",
    "                sale_made = False\n",
    "                revenue = 0\n",
    "                # Still need counterfactuals for learning and valuation for fairness\n",
    "                _, _, sale_made_full, revenue_full, valuation = env.simulate_round(price)\n",
    "            else:\n",
    "                # Normal interaction: simulate customer decision\n",
    "                sale_made, revenue, sale_made_full, revenue_full, valuation = env.simulate_round(price)\n",
    "\n",
    "            # Store the actual customer valuation for fair theoretical optimum comparison\n",
    "            actual_valuations.append(valuation)\n",
    "\n",
    "            # Update agent with observed outcomes and counterfactuals\n",
    "            agent.update(revenue, sale_made, revenue_full, sale_made_full)\n",
    "\n",
    "            # Record results for analysis\n",
    "            selected_prices.append(price)\n",
    "            revenues.append(revenue)\n",
    "            sales.append(sale_made)\n",
    "            total_revenue += revenue\n",
    "            cumulative_revenue.append(total_revenue)\n",
    "\n",
    "            # Progress reporting\n",
    "            if verbose and (t + 1) % (T//10) == 0:\n",
    "                current_performance = total_revenue / (t + 1)\n",
    "                print(f\"Round {t + 1:,}: Avg revenue = {current_performance:.4f}, \"\n",
    "                      f\"Inventory = {agent.remaining_inventory}, \"\n",
    "                      f\"Sales rate = {sum(sales)/(t+1)*100:.1f}%\")\n",
    "\n",
    "        # Record final agent statistics\n",
    "        best_reward_value = agent.get_max_reward()\n",
    "        best_reward.append(best_reward_value)\n",
    "        best_price_value = agent_params['prices'][agent.get_argmax_reward()]\n",
    "        best_price.append(best_price_value)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\\n=== Simulation #{sim + 1} Results ===\")\n",
    "            print(f\"Total revenue: {total_revenue:.2f}\")\n",
    "            print(f\"Average revenue per round: {total_revenue / T:.6f}\")\n",
    "            print(f\"Total sales: {sum(sales):,} units\")\n",
    "            print(f\"Sales rate: {sum(sales)/T*100:.1f}%\")\n",
    "            print(f\"Inventory utilization: {(agent_params['P'] - agent.remaining_inventory)/agent_params['P']*100:.1f}%\")\n",
    "            print(f\"Agent's best price: {best_price[-1]:.3f}\")\n",
    "            print(f\"First inventory empty: {first_inventory_empty if first_inventory_empty else 'Never'}\")\n",
    "\n",
    "    return {\n",
    "        'selected_prices': selected_prices,\n",
    "        'revenues': revenues,\n",
    "        'sales': sales,\n",
    "        'cumulative_revenue': cumulative_revenue,\n",
    "        'best_price': best_price,\n",
    "        'best_reward': best_reward,\n",
    "        'first_inventory_empty': first_inventory_empty,\n",
    "        'total_revenue': total_revenue,\n",
    "        'agent': agent,\n",
    "        'actual_valuations': actual_valuations\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e63f048",
   "metadata": {},
   "source": [
    "## Run The simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b77733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SIMULATION CONFIGURATION AND EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "# Core simulation parameters\n",
    "T = 10000                        # Time horizon (number of rounds)\n",
    "inventory = int(T * 0.8)         # Initial inventory: 80% of time horizon\n",
    "\n",
    "eta = 0.1                        # Learning rate for Lagrangian multiplier\n",
    "\n",
    "print(\"=== SIMULATION CONFIGURATION ===\")\n",
    "print(f\"Time horizon (T): {T:,} rounds\")\n",
    "print(f\"Inventory constraint (P): {inventory:,} units\")\n",
    "print(f\"Inventory-to-time ratio: {inventory/T:.1%}\")\n",
    "print(f\"Lagrangian learning rate (η): {eta}\")\n",
    "\n",
    "# === CREATE NON-STATIONARY CUSTOMER VALUATIONS ===\n",
    "# Generate different customer preference distributions for each round\n",
    "# This creates the non-stationary environment where customer valuations shift over time\n",
    "\n",
    "np.random.seed(42)  # For reproducibility of experiments\n",
    "\n",
    "# Generate time-varying parameters for customer valuations\n",
    "means = np.random.uniform(0.4, 0.6, size=T)    # Mean valuations vary between 0.4-0.6\n",
    "stds = np.random.uniform(0.1, 0.2, size=T)     # Standard deviations vary between 0-0.1\n",
    "\n",
    "# Create list of normal distributions (one for each round)\n",
    "valuation_dists = [\n",
    "    stats.norm(loc=means[t], scale=stds[t]) \n",
    "    for t in range(T)\n",
    "]\n",
    "\n",
    "print(f\"\\nNon-stationarity characteristics:\")\n",
    "print(f\"Mean valuation range: [{np.min(means):.3f}, {np.max(means):.3f}]\")\n",
    "print(f\"Std deviation range: [{np.min(stds):.3f}, {np.max(stds):.3f}]\")\n",
    "print(f\"Distribution changes: Every round (maximum non-stationarity)\")\n",
    "\n",
    "# === AGENT CONFIGURATION ===\n",
    "# Define the set of discrete price options available to the agent\n",
    "price_options = np.arange(0.1, 0.9, 1/7)  # 7 evenly spaced prices from 0.1 to ~0.8\n",
    "\n",
    "agent_params = {\n",
    "    'prices': price_options,     # Available price options\n",
    "    'valuation': valuation_dists,  # Customer valuation distributions\n",
    "    'P': inventory,              # Inventory constraint\n",
    "    'T': T,                      # Time horizon\n",
    "    'eta': eta,                  # Learning rate for Lagrangian multiplier\n",
    "    'algorithm': 'exp3'          # Algorithm to use: 'hedge' or 'exp3'\n",
    "}\n",
    "\n",
    "print(f\"\\n=== AGENT CONFIGURATION ===\")\n",
    "print(f\"Number of price options: {len(agent_params['prices'])}\")\n",
    "print(f\"Price range: [{agent_params['prices'][0]:.3f}, {agent_params['prices'][-1]:.3f}]\")\n",
    "print(f\"Price granularity: {(agent_params['prices'][1] - agent_params['prices'][0]):.3f}\")\n",
    "print(f\"Target selling rate (ρ): {inventory/T:.4f} units/round\")\n",
    "\n",
    "# Theoretical analysis preview\n",
    "hedge_lr = np.sqrt(np.log(np.size(price_options)) / T)\n",
    "print(f\"Hedge learning rate: {hedge_lr:.6f}\")\n",
    "print(f\"Expected regret bound: O(√T log K) ≈ {np.sqrt(T * np.log(np.size(price_options))):.0f}\")\n",
    "\n",
    "# === RUN SIMULATION ===\n",
    "print(f\"\\n=== EXECUTING SIMULATION ===\")\n",
    "print(\"Starting primal-dual pricing experiment...\")\n",
    "\n",
    "results = run_simulator(\n",
    "    T=T,\n",
    "    valuation_dist=valuation_dists,\n",
    "    agent_params=agent_params,\n",
    "    n_simulations=1,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# === EXTRACT AND SUMMARIZE RESULTS ===\n",
    "selected_prices = results['selected_prices']\n",
    "revenues = results['revenues']\n",
    "sales = results['sales']\n",
    "cumulative_revenue = results['cumulative_revenue']\n",
    "best_price = results['best_price']\n",
    "first_inventory_empty = results['first_inventory_empty']\n",
    "total_revenue = results['total_revenue']\n",
    "best_reward = results['best_reward']\n",
    "agent = results['agent']\n",
    "\n",
    "print(f\"\\n=== FINAL SIMULATION SUMMARY ===\")\n",
    "print(f\"✓ Simulation completed successfully\")\n",
    "print(f\"Performance Metrics:\")\n",
    "print(f\"   • Total revenue: {total_revenue:.2f}\")\n",
    "print(f\"   • Average revenue per round: {total_revenue / T:.6f}\")\n",
    "print(f\"   • Total units sold: {sum(sales):,}\")\n",
    "print(f\"   • Sales rate: {sum(sales)/T*100:.1f}%\")\n",
    "print(f\"   • Final inventory: {agent.remaining_inventory:,} units\")\n",
    "print(f\"   • Inventory utilization: {(inventory - agent.remaining_inventory)/inventory*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nAgent Learning Results:\")\n",
    "print(f\"   • Best price discovered: {best_price[0]:.3f}\")\n",
    "print(f\"   • Inventory depleted at round: {first_inventory_empty if first_inventory_empty else 'Never'}\")\n",
    "print(f\"   • Constraint management: {'✓ Successful' if agent.remaining_inventory >= 0 else '⚠ Violated'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbd9286",
   "metadata": {},
   "source": [
    "## Theoretical Optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9196ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# THEORETICAL OPTIMUM CALCULATION WITH INVENTORY CONSTRAINTS\n",
    "# =============================================================================\n",
    "\n",
    "def compute_theoretical_optimum(agent_params, valuation_dist, T, actual_valuations=None):\n",
    "    \"\"\"\n",
    "    Compute optimal policy that manages budget dynamically over time.\n",
    "    Uses a threshold-based approach that considers inventory scarcity.\n",
    "    \"\"\"\n",
    "    prices = agent_params['prices']\n",
    "    P = agent_params['P']\n",
    "    \n",
    "    # Get actual valuations\n",
    "    if actual_valuations is None:\n",
    "        # Use same random seed as simulation for fair comparison\n",
    "        np.random.seed(42)\n",
    "        actual_valuations = []\n",
    "        for t in range(T):\n",
    "            current_dist = valuation_dist[t]\n",
    "            valuation = current_dist.rvs()\n",
    "            actual_valuations.append(valuation)\n",
    "    \n",
    "    # Dynamic threshold based on remaining inventory ratio\n",
    "    selling_decisions = []\n",
    "    inventory_remaining = P\n",
    "    \n",
    "    for t in range(T):\n",
    "        remaining_rounds = T - t\n",
    "        customer_valuation = actual_valuations[t]\n",
    "        \n",
    "        # Dynamic threshold: higher when inventory is scarce\n",
    "        inventory_ratio = inventory_remaining / max(remaining_rounds, 1)\n",
    "        \n",
    "        # Threshold increases as inventory becomes relatively scarce\n",
    "        if inventory_ratio < 0.1:  # Scarce inventory\n",
    "            threshold = np.percentile([v for v in actual_valuations[t:]], 80)\n",
    "        elif inventory_ratio < 0.5:  # Moderate inventory\n",
    "            threshold = np.percentile([v for v in actual_valuations[t:]], 60)\n",
    "        else:  # Abundant inventory\n",
    "            threshold = np.percentile([v for v in actual_valuations[t:]], 40)\n",
    "        \n",
    "        # Decision: sell only if customer valuation exceeds threshold AND we have inventory\n",
    "        if inventory_remaining > 0 and customer_valuation >= threshold:\n",
    "            # Find best price for this customer\n",
    "            valid_prices = [p for p in prices if p <= customer_valuation]\n",
    "            if valid_prices:\n",
    "                best_price = max(valid_prices)\n",
    "                selling_decisions.append({\n",
    "                    'round': t,\n",
    "                    'price': best_price,\n",
    "                    'revenue': best_price,\n",
    "                    'sell': True\n",
    "                })\n",
    "                inventory_remaining -= 1\n",
    "            else:\n",
    "                selling_decisions.append({\n",
    "                    'round': t,\n",
    "                    'price': 0,\n",
    "                    'revenue': 0,\n",
    "                    'sell': False\n",
    "                })\n",
    "        else:\n",
    "            selling_decisions.append({\n",
    "                'round': t,\n",
    "                'price': 0,\n",
    "                'revenue': 0,\n",
    "                'sell': False\n",
    "            })\n",
    "    \n",
    "    # Convert to expected format for plotting code\n",
    "    total_optimal_revenue = sum([decision['revenue'] for decision in selling_decisions])\n",
    "    optimal_revenue_per_round = total_optimal_revenue / T\n",
    "    \n",
    "    # Create per-round revenue list\n",
    "    opt_revenues_per_round = [decision['revenue'] for decision in selling_decisions]\n",
    "    \n",
    "    # Compute optimal price distribution among selected opportunities\n",
    "    opt_dist = np.zeros(len(prices))\n",
    "    selected_opportunities = [decision for decision in selling_decisions if decision['sell']]\n",
    "    \n",
    "    for decision in selected_opportunities:\n",
    "        if decision['price'] > 0:\n",
    "            # Find price index\n",
    "            price_idx = np.where(np.abs(prices - decision['price']) < 1e-6)[0]\n",
    "            if len(price_idx) > 0:\n",
    "                opt_dist[price_idx[0]] += 1\n",
    "    \n",
    "    if len(selected_opportunities) > 0:\n",
    "        opt_dist = opt_dist / len(selected_opportunities)  # Normalize by number of sales\n",
    "    \n",
    "    return {\n",
    "        'opt_dist': opt_dist,\n",
    "        'optimal_revenue_per_round': optimal_revenue_per_round,\n",
    "        'opt_revenues_per_round': opt_revenues_per_round,\n",
    "        'selected_opportunities': selected_opportunities,\n",
    "        'actual_valuations': actual_valuations\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f0a6de",
   "metadata": {},
   "source": [
    "## Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7362e824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZATION AND ANALYSIS EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "# Import matplotlib if not already imported\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"Generating comprehensive visualizations and analysis...\")\n",
    "print(\"Plots covering aspects of algorithm performance\")\n",
    "print(\"Regret calculations with proper theoretical baseline\")\n",
    "print(\"Policy comparisons and convergence analysis\")\n",
    "\n",
    "# Extract actual valuations from results\n",
    "actual_valuations = results.get('actual_valuations', None)\n",
    "if actual_valuations is None:\n",
    "    print(\"--- No actual valuations found in results, will use same random seed for fair comparison ---\")\n",
    "\n",
    "print(f\"Number of actual valuations: {len(actual_valuations) if actual_valuations else 'None'}\")\n",
    "print(f\"Sample valuations: {actual_valuations[:5] if actual_valuations else 'N/A'}\")\n",
    "\n",
    "try:\n",
    "    # Debug: Check what the function returns\n",
    "    result = compute_theoretical_optimum(agent_params, valuation_dists, T, actual_valuations=actual_valuations)\n",
    "    print(f\"Function returned type: {type(result)}\")\n",
    "    print(f\"Function returned keys: {list(result.keys()) if isinstance(result, dict) else 'Not a dictionary'}\")\n",
    "    \n",
    "    # Extract values from the result dictionary\n",
    "    opt_dist = result['opt_dist']\n",
    "    optimal_revenue = result['optimal_revenue_per_round']\n",
    "    true_rewards = result['opt_revenues_per_round']\n",
    "    selected_opportunities = result['selected_opportunities']\n",
    "    \n",
    "    print(f\"✓ Theoretical optimum computed: {sum(true_rewards):.2f} total revenue\")\n",
    "\n",
    "    # === REGRET CALCULATION ===\n",
    "    theoretical_optimal_total = sum(true_rewards)  # Total: sum of actual optimal revenues per round\n",
    "    total_revenue = sum(results['revenues'])\n",
    "\n",
    "    # Regret calculation using proper baseline\n",
    "    regret_per_round = []\n",
    "    cumulative_optimal_revenue = []  # Track cumulative optimal for correct plotting\n",
    "\n",
    "    for t in range(T):\n",
    "        # Instantaneous regret = optimal_revenue_at_t - actual_revenue_at_t\n",
    "        optimal_at_t = true_rewards[t]\n",
    "        actual_at_t = results['revenues'][t]\n",
    "        instantaneous_regret = optimal_at_t - actual_at_t\n",
    "        regret_per_round.append(instantaneous_regret)\n",
    "        \n",
    "        # Cumulative optimal for correct comparison line\n",
    "        cumulative_optimal_revenue.append(sum(true_rewards[:t+1]))\n",
    "\n",
    "    regret_cumulative = np.cumsum(regret_per_round)\n",
    "    final_performance = (total_revenue / theoretical_optimal_total) * 100 if theoretical_optimal_total > 0 else 0\n",
    "\n",
    "    print(f\"✓ Regret calculation completed\")\n",
    "    print(f\"Performance Summary:\")\n",
    "    print(f\"   • Agent total revenue: {total_revenue:.2f}\")\n",
    "    print(f\"   • Optimal total revenue: {theoretical_optimal_total:.2f}\")\n",
    "    print(f\"   • Performance: {final_performance:.1f}% of optimal\")\n",
    "    print(f\"   • Total regret: {regret_cumulative[-1]:.2f}\")\n",
    "    print(f\"   • Average regret per round: {regret_cumulative[-1]/T:.6f}\")\n",
    "\n",
    "    # Price frequency analysis\n",
    "    price_to_idx = {p: i for i, p in enumerate(agent_params['prices'])}\n",
    "    price_indices = []\n",
    "    for p in results['selected_prices']:\n",
    "        if not (isinstance(p, float) and np.isnan(p)) and p in price_to_idx:\n",
    "            price_indices.append(price_to_idx[p])\n",
    "\n",
    "    if price_indices:\n",
    "        price_counts = np.bincount(price_indices, minlength=len(agent_params['prices']))\n",
    "    else:\n",
    "        price_counts = np.zeros(len(agent_params['prices']))\n",
    "\n",
    "    # === VISUALIZATION ===\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "    # 1. Cumulative Revenue vs Optimal\n",
    "    axes[0].plot(results['cumulative_revenue'], label='Primal-Dual Agent Revenue', \n",
    "                    linewidth=3, color='blue', alpha=0.8)\n",
    "    axes[0].plot(cumulative_optimal_revenue, \n",
    "                    label='Theoretical Optimal', \n",
    "                    linestyle='--', linewidth=3, color='red', alpha=0.8)\n",
    "\n",
    "    axes[0].set_xlabel('Round', fontsize=12)\n",
    "    axes[0].set_ylabel('Cumulative Revenue', fontsize=12)\n",
    "    axes[0].set_title('Revenue Performance Comparison', fontsize=14, fontweight='bold')\n",
    "    axes[0].legend(fontsize=11)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    # 2. Regret Analysis\n",
    "    t_vals = np.arange(1, T + 1)\n",
    "    axes[1].plot(regret_cumulative, color='blue', linewidth=3, \n",
    "                    label='Actual Cumulative Regret', alpha=0.8)\n",
    "\n",
    "    # Theoretical bound\n",
    "    K = len(agent_params['prices'])\n",
    "    sqrt_t_log_t = np.sqrt(t_vals) * np.log(t_vals + 1)\n",
    "    max_possible_regret_per_round = np.max(agent_params['prices'])\n",
    "    bound_scale = max_possible_regret_per_round * np.sqrt(np.log(K))\n",
    "    primal_dual_bound = bound_scale * sqrt_t_log_t\n",
    "    \n",
    "    if (agent_params['algorithm'] == 'hedge'):\n",
    "        theoretical_bound = bound_scale * np.sqrt(T * np.log(T))\n",
    "    else:\n",
    "        theoretical_bound = np.sqrt(T)\n",
    "\n",
    "\n",
    "\n",
    "    axes[1].plot(t_vals, primal_dual_bound, '--', color='red', alpha=0.7, linewidth=2,\n",
    "             label=f\"Primal-Dual Bound {'O(sqrt(T log T))' if agent_params['algorithm'] == 'hedge' else 'O(sqrt(T))'}\")\n",
    "\n",
    "    final_regret_rate = regret_cumulative[-1] / T\n",
    "    \n",
    "\n",
    "    bound_ratio = regret_cumulative[-1] / theoretical_bound if theoretical_bound > 0 else 0\n",
    "\n",
    "    axes[1].set_xlabel('Round', fontsize=12)\n",
    "    axes[1].set_ylabel('Cumulative Regret', fontsize=12)\n",
    "    axes[1].set_title('Regret Growth Analysis', fontsize=14, fontweight='bold')\n",
    "    axes[1].legend(fontsize=11)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"All visualizations completed successfully!\")\n",
    "    print(f\"Key Insight: The agent achieves {final_performance:.1f}% of the optimal performance\")\n",
    "    print(f\"This represents excellent performance for online learning in a non-stationary environment\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during plotting: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    print(\"Please check the data and function definitions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
