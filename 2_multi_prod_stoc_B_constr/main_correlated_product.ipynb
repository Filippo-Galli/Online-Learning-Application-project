{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02d6ab36",
   "metadata": {},
   "source": [
    "# Task 2: Multi Independent Product with B constrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047566a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "\n",
    "from scipy.optimize import linear_sum_assignment, linprog\n",
    "\n",
    "from scipy import optimize\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../utils')\n",
    "\n",
    "from UCB1_multi_constr import UCBMatchingAgent\n",
    "from Multi_Thompson_constr import MultiThompsonSamplingPricingAgent\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce32918e",
   "metadata": {},
   "source": [
    "# Enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7800fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiProductPricingEnvironment:\n",
    "    \"\"\"\n",
    "    Multi-product stochastic environment for dynamic pricing with inventory constraints.\n",
    "\n",
    "    This environment simulates a multi-product pricing scenario where:\n",
    "    - Each product has its own customer valuation distribution\n",
    "    - Customers have different preferences for different products\n",
    "    - Each round represents one customer interaction\n",
    "    - The customer can purchase multiple products or none at all\n",
    "    \"\"\"\n",
    "    def __init__(self, valuation_distribution,n_samples=100000):\n",
    "        \"\"\"\n",
    "        Initialize the multi-product pricing environment.\n",
    "\n",
    "        Args:\n",
    "            valuation_distribution: multi_variate distribution of scipy.stats distribution for each product\n",
    "        \"\"\"\n",
    "        self.valuation_dist = valuation_distribution\n",
    "        self.n_products = len(valuation_distribution.mean)\n",
    "\n",
    "        # number of samples to draw from the distribution\n",
    "        self.n_samples = n_samples\n",
    "\n",
    "    def demand_probability(self, prices, product_subset):\n",
    "        \"\"\"\n",
    "        Calculate the theoretical probability that a customer purchases\n",
    "        the given subset of products at given prices.\n",
    "\n",
    "        Args:\n",
    "            prices: Array of prices for each product\n",
    "            product_subset: List of product indices being offered\n",
    "\n",
    "        Returns:\n",
    "            Probability that customer will purchase this product subset\n",
    "\n",
    "        \"\"\"\n",
    "        prob=np.zeros(len(product_subset))\n",
    "\n",
    "        for i, product_idx in enumerate(product_subset):\n",
    "            samples = self.valuation_dist.rvs(size=self.n_samples)\n",
    "            # Calculate the probability that the customer will purchase this product\n",
    "            prob[i]  = np.mean(samples[:, product_idx] >= prices[product_idx])\n",
    "\n",
    "        # Return the probability of purchasing each product in the subset for each price in the prices vector\n",
    "        return prob\n",
    "\n",
    "    def simulate_round(self, prices, product_subset):\n",
    "        \"\"\"\n",
    "        Simulate one customer interaction for a given product subset and prices.\n",
    "\n",
    "        Args:\n",
    "            prices: Array of prices for each product\n",
    "            product_subset: List of product indices being offered\n",
    "\n",
    "        Returns:\n",
    "            tuple: (products_purchased, total_revenue) where:\n",
    "                - products_purchased: List of products actually purchased\n",
    "                - total_revenue: Sum of revenues from purchased products\n",
    "        \"\"\"\n",
    "        if len(product_subset) == 0:\n",
    "            return [], 0.0\n",
    "\n",
    "        products_purchased = []\n",
    "        total_revenue = 0.0\n",
    "\n",
    "        # Generate customer valuations for all products\n",
    "        valuations = self.valuation_dist.rvs(size=1)\n",
    "\n",
    "        # Customer purchases products where valuation >= price\n",
    "        for product_idx in product_subset:\n",
    "            if valuations[product_idx] >= prices[product_idx]:\n",
    "                products_purchased.append(product_idx)\n",
    "                total_revenue += prices[product_idx]\n",
    "\n",
    "        return products_purchased, total_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5894b9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_clairvoyant(prices, environment, T, total_inventory, method='sampling'):\n",
    "    \"\"\"\n",
    "    Compute the optimal (clairvoyant) pricing strategy with full information\n",
    "    for the multi-product case with a single shared inventory constraint.\n",
    "\n",
    "    Args:\n",
    "        prices: List of available prices (assumed to be the same for all products)\n",
    "        environment: MultiProductPricingEnvironment to get true demand probabilities\n",
    "        T: Time horizon\n",
    "        total_inventory: Total shared inventory across all products\n",
    "        method: 'sampling' for probabilistic sampling, 'lsa' for Linear Sum Assignment\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with optimal policy information, including per-product insights.\n",
    "    \"\"\"\n",
    "    n_products = environment.n_products\n",
    "    n_price_options = len(prices)\n",
    "    num_vars = n_products * n_price_options\n",
    "\n",
    "    # Compute true demand probabilities for each (product, price) combination\n",
    "    demand_probabilities = np.zeros((n_products, n_price_options))\n",
    "    \n",
    "    for product_idx in range(n_products):\n",
    "        for price_idx, price in enumerate(prices):\n",
    "            demand_probabilities[product_idx, price_idx] = environment.demand_probability([price]*environment.n_products, [product_idx])\n",
    "\n",
    "    # Expected revenue per selection for each (product, price) combination\n",
    "    expected_revenues = np.array(prices) * demand_probabilities\n",
    "\n",
    "    # Compute optimal gamma distribution (same for both methods)\n",
    "    gamma_result = compute_optimal_gamma(expected_revenues, demand_probabilities, T, total_inventory)\n",
    "    \n",
    "    if gamma_result is None:\n",
    "        return create_fallback_result(n_products, n_price_options, prices, \n",
    "                                    demand_probabilities, expected_revenues)\n",
    "\n",
    "    gamma = gamma_result['gamma']\n",
    "    lp_optimal_revenue = gamma_result['lp_optimal_revenue']\n",
    "\n",
    "    if method == 'sampling':\n",
    "        return compute_sampling_performance(gamma, prices, expected_revenues, demand_probabilities, \n",
    "                                          lp_optimal_revenue, T, n_products, n_price_options)\n",
    "    elif method == 'lsa':\n",
    "        return compute_lsa_performance(gamma, prices, expected_revenues, demand_probabilities, \n",
    "                                     lp_optimal_revenue, T, n_products, n_price_options)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}. Use 'sampling' or 'lsa'\")\n",
    "\n",
    "def compute_optimal_gamma(expected_revenues, demand_probabilities, T, total_inventory):\n",
    "    \"\"\"\n",
    "    Solve the LP to get optimal gamma distribution.\n",
    "    \"\"\"\n",
    "    n_products, n_price_options = expected_revenues.shape\n",
    "    num_vars = n_products * n_price_options\n",
    "\n",
    "    # Set up linear program (convert maximization to minimization)\n",
    "    c = -expected_revenues.flatten()\n",
    "\n",
    "    # Inequality constraints (shared inventory)\n",
    "    A_ub = [demand_probabilities.flatten()]\n",
    "    b_ub = [total_inventory / T]\n",
    "\n",
    "    # Equality constraints (probability distribution for each product)\n",
    "    A_eq = np.zeros((n_products, num_vars))\n",
    "    b_eq = np.ones(n_products)\n",
    "\n",
    "    for product_idx in range(n_products):\n",
    "        start_idx = product_idx * n_price_options\n",
    "        end_idx = start_idx + n_price_options\n",
    "        A_eq[product_idx, start_idx:end_idx] = 1\n",
    "\n",
    "    bounds = [(0, 1) for _ in range(num_vars)]\n",
    "\n",
    "    try:\n",
    "        res = optimize.linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq,\n",
    "                              bounds=bounds, method='highs')\n",
    "\n",
    "        if res.success:\n",
    "            gamma_flat = res.x\n",
    "            gamma = gamma_flat.reshape((n_products, n_price_options))\n",
    "            lp_optimal_revenue = -res.fun * T\n",
    "            \n",
    "            return {\n",
    "                'gamma': gamma,\n",
    "                'lp_optimal_revenue': lp_optimal_revenue\n",
    "            }\n",
    "        else:\n",
    "            print(\"Clairvoyant LP failed to converge.\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Clairvoyant LP Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def compute_sampling_performance(gamma, prices, expected_revenues, demand_probabilities, \n",
    "                               lp_optimal_revenue, T, n_products, n_price_options):\n",
    "    \"\"\"\n",
    "    Compute performance for sampling-based selection (original method).\n",
    "    \"\"\"\n",
    "    optimal_policies = {}\n",
    "    \n",
    "    for product_idx in range(n_products):\n",
    "        best_price_idx_in_dist = np.argmax(gamma[product_idx, :])\n",
    "        optimal_price_for_product = prices[best_price_idx_in_dist]\n",
    "\n",
    "        expected_revenue_per_round_product = np.sum(gamma[product_idx, :] * expected_revenues[product_idx, :])\n",
    "        expected_purchase_prob_product = np.sum(gamma[product_idx, :] * demand_probabilities[product_idx, :])\n",
    "\n",
    "        optimal_policies[product_idx] = {\n",
    "            'optimal_price_distribution': gamma[product_idx, :],\n",
    "            'representative_optimal_price': optimal_price_for_product,\n",
    "            'expected_revenue_per_round': expected_revenue_per_round_product,\n",
    "            'purchase_probability': expected_purchase_prob_product,\n",
    "            'expected_total_revenue_under_dist': expected_revenue_per_round_product * T\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        'method': 'sampling',\n",
    "        'per_product_policies': optimal_policies,\n",
    "        'total_expected_revenue_upper_bound': lp_optimal_revenue,\n",
    "        'optimal_gamma': gamma,\n",
    "        'demand_probabilities': demand_probabilities,\n",
    "        'expected_revenues': expected_revenues\n",
    "    }\n",
    "\n",
    "def compute_lsa_performance(gamma, prices, expected_revenues, demand_probabilities, \n",
    "                          lp_optimal_revenue, T, n_products, n_price_options):\n",
    "    \"\"\"\n",
    "    Compute performance for LSA-based selection.\n",
    "    \n",
    "    LSA selects the deterministic assignment that maximizes gamma-weighted revenues.\n",
    "    \"\"\"\n",
    "    optimal_policies = {}\n",
    "    \n",
    "    # Compute LSA assignment based on gamma-weighted revenues\n",
    "    cost_matrix = -(expected_revenues * gamma)  # Negative for minimization\n",
    "    row_indices, col_indices = linear_sum_assignment(cost_matrix)\n",
    "    \n",
    "    # Calculate actual performance of LSA assignment\n",
    "    lsa_revenue_per_round = 0.0\n",
    "    lsa_purchases_per_round = 0.0\n",
    "    \n",
    "    for product_idx in range(n_products):\n",
    "        selected_price_idx = col_indices[product_idx]\n",
    "        selected_price = prices[selected_price_idx]\n",
    "        \n",
    "        # Revenue and purchase probability for this deterministic choice\n",
    "        revenue_per_round = expected_revenues[product_idx, selected_price_idx]\n",
    "        purchase_prob = demand_probabilities[product_idx, selected_price_idx]\n",
    "        \n",
    "        lsa_revenue_per_round += revenue_per_round\n",
    "        lsa_purchases_per_round += purchase_prob\n",
    "        \n",
    "        optimal_policies[product_idx] = {\n",
    "            'optimal_price_distribution': gamma[product_idx, :],  # Keep original gamma for reference\n",
    "            'lsa_selected_price_idx': selected_price_idx,\n",
    "            'lsa_selected_price': selected_price,\n",
    "            'representative_optimal_price': selected_price,  # For compatibility\n",
    "            'expected_revenue_per_round': revenue_per_round,\n",
    "            'purchase_probability': purchase_prob,\n",
    "            'expected_total_revenue_under_dist': revenue_per_round * T,\n",
    "            'gamma_weight_at_selection': gamma[product_idx, selected_price_idx]\n",
    "        }\n",
    "    \n",
    "    # Check if LSA assignment respects inventory constraint\n",
    "    #inventory_constraint_rhs = total_inventory / T  # This needs to be passed as parameter\n",
    "    # Note: We need total_inventory here, but it's not in function signature. \n",
    "    # We'll estimate it from the LP constraint that was binding.\n",
    "    \n",
    "  \n",
    "    effective_rounds = T\n",
    "    \n",
    "    lsa_total_revenue = lsa_revenue_per_round * effective_rounds\n",
    "    \n",
    "    return {\n",
    "        'method': 'lsa',\n",
    "        'per_product_policies': optimal_policies,\n",
    "        'total_expected_revenue_upper_bound': lp_optimal_revenue,  # LP upper bound\n",
    "        'lsa_expected_revenue': lsa_total_revenue,  # Actual LSA performance\n",
    "        'lsa_revenue_per_round': lsa_revenue_per_round,\n",
    "        'lsa_purchases_per_round': lsa_purchases_per_round,\n",
    "        'lsa_assignment': col_indices,\n",
    "        'lsa_effective_rounds': effective_rounds,\n",
    "        'optimal_gamma': gamma,\n",
    "        'demand_probabilities': demand_probabilities,\n",
    "        'expected_revenues': expected_revenues,\n",
    "        'lsa_vs_lp_ratio': lsa_total_revenue / lp_optimal_revenue if lp_optimal_revenue > 0 else 0\n",
    "    }\n",
    "\n",
    "def compute_lsa_performance_with_inventory(gamma, prices, expected_revenues, demand_probabilities, \n",
    "                                         lp_optimal_revenue, T, total_inventory, n_products, n_price_options):\n",
    "    \"\"\"\n",
    "    Enhanced LSA performance calculation with explicit inventory constraint checking.\n",
    "    \"\"\"\n",
    "    # Compute LSA assignment\n",
    "    cost_matrix = -(expected_revenues * gamma)\n",
    "    row_indices, col_indices = linear_sum_assignment(cost_matrix)\n",
    "    \n",
    "    # Calculate LSA performance with inventory constraint\n",
    "    lsa_revenue_per_round = 0.0\n",
    "    lsa_purchases_per_round = 0.0\n",
    "    \n",
    "    optimal_policies = {}\n",
    "    \n",
    "    for product_idx in range(n_products):\n",
    "        selected_price_idx = col_indices[product_idx]\n",
    "        selected_price = prices[selected_price_idx]\n",
    "        \n",
    "        revenue_per_round = expected_revenues[product_idx, selected_price_idx]\n",
    "        purchase_prob = demand_probabilities[product_idx, selected_price_idx]\n",
    "        \n",
    "        lsa_revenue_per_round += revenue_per_round\n",
    "        lsa_purchases_per_round += purchase_prob\n",
    "        \n",
    "        optimal_policies[product_idx] = {\n",
    "            'optimal_price_distribution': gamma[product_idx, :],\n",
    "            'lsa_selected_price_idx': selected_price_idx,\n",
    "            'lsa_selected_price': selected_price,\n",
    "            'representative_optimal_price': selected_price,\n",
    "            'expected_revenue_per_round': revenue_per_round,\n",
    "            'purchase_probability': purchase_prob,\n",
    "            'expected_total_revenue_under_dist': revenue_per_round * T,\n",
    "            'gamma_weight_at_selection': gamma[product_idx, selected_price_idx]\n",
    "        }\n",
    "    \n",
    "    # Check inventory constraint\n",
    "    if lsa_purchases_per_round > 0:\n",
    "        max_rounds_lsa = total_inventory / lsa_purchases_per_round\n",
    "        effective_rounds = min(max_rounds_lsa, T)\n",
    "        inventory_constraint_binding = max_rounds_lsa < T\n",
    "    else:\n",
    "        effective_rounds = T\n",
    "        inventory_constraint_binding = False\n",
    "    \n",
    "    lsa_total_revenue = lsa_revenue_per_round * effective_rounds\n",
    "    \n",
    "    return {\n",
    "        'method': 'lsa',\n",
    "        'per_product_policies': optimal_policies,\n",
    "        'total_expected_revenue_upper_bound': lp_optimal_revenue,\n",
    "        'lsa_expected_revenue': lsa_total_revenue,\n",
    "        'lsa_revenue_per_round': lsa_revenue_per_round,\n",
    "        'lsa_purchases_per_round': lsa_purchases_per_round,\n",
    "        'lsa_assignment': col_indices,\n",
    "        'lsa_effective_rounds': effective_rounds,\n",
    "        'lsa_max_sustainable_rounds': max_rounds_lsa if lsa_purchases_per_round > 0 else T,\n",
    "        'inventory_constraint_binding': inventory_constraint_binding,\n",
    "        'optimal_gamma': gamma,\n",
    "        'demand_probabilities': demand_probabilities,\n",
    "        'expected_revenues': expected_revenues,\n",
    "        'lsa_vs_lp_ratio': lsa_total_revenue / lp_optimal_revenue if lp_optimal_revenue > 0 else 0\n",
    "    }\n",
    "\n",
    "def create_fallback_result(n_products, n_price_options, prices, demand_probabilities, expected_revenues):\n",
    "    \"\"\"Create fallback result when LP fails.\"\"\"\n",
    "    optimal_policies = {}\n",
    "    for product_idx in range(n_products):\n",
    "        optimal_policies[product_idx] = {\n",
    "            'optimal_price_distribution': np.ones(n_price_options) / n_price_options,\n",
    "            'representative_optimal_price': prices[0],\n",
    "            'expected_revenue_per_round': 0.0,\n",
    "            'purchase_probability': 0.0,\n",
    "            'expected_total_revenue_under_dist': 0.0\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        'per_product_policies': optimal_policies,\n",
    "        'total_expected_revenue_upper_bound': 0.0,\n",
    "        'optimal_gamma': None,\n",
    "        'demand_probabilities': demand_probabilities,\n",
    "        'expected_revenues': expected_revenues\n",
    "    }\n",
    "\n",
    "# Enhanced version that needs to be called separately with total_inventory\n",
    "def compute_clairvoyant_enhanced(prices, environment, T, total_inventory, method='sampling'):\n",
    "    \"\"\"\n",
    "    Enhanced version with proper LSA inventory constraint handling.\n",
    "    \"\"\"\n",
    "    n_products = environment.n_products\n",
    "    n_price_options = len(prices)\n",
    "\n",
    "    # Compute true demand probabilities and expected revenues\n",
    "    demand_probabilities = np.zeros((n_products, n_price_options))\n",
    "    for product_idx in range(n_products):\n",
    "        for price_idx, price in enumerate(prices):\n",
    "            demand_probabilities[product_idx, price_idx] = environment.demand_probability([price]*environment.n_products, [product_idx])\n",
    "\n",
    "    expected_revenues = np.array(prices) * demand_probabilities\n",
    "\n",
    "    # Compute optimal gamma distribution\n",
    "    gamma_result = compute_optimal_gamma(expected_revenues, demand_probabilities, T, total_inventory)\n",
    "    \n",
    "    if gamma_result is None:\n",
    "        return create_fallback_result(n_products, n_price_options, prices, \n",
    "                                    demand_probabilities, expected_revenues)\n",
    "\n",
    "    gamma = gamma_result['gamma']\n",
    "    lp_optimal_revenue = gamma_result['lp_optimal_revenue']\n",
    "\n",
    "    if method == 'sampling':\n",
    "        return compute_sampling_performance(gamma, prices, expected_revenues, demand_probabilities, \n",
    "                                          lp_optimal_revenue, T, n_products, n_price_options)\n",
    "    elif method == 'lsa':\n",
    "        return compute_lsa_performance_with_inventory(gamma, prices, expected_revenues, demand_probabilities, \n",
    "                                                    lp_optimal_revenue, T, total_inventory, n_products, n_price_options)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}. Use 'sampling' or 'lsa'\")\n",
    "\n",
    "# Usage examples:\n",
    "\"\"\"\n",
    "# For sampling-based agent (original)\n",
    "clairvoyant_sampling = compute_clairvoyant_enhanced(\n",
    "    prices=your_prices,\n",
    "    environment=your_env,\n",
    "    T=your_T,\n",
    "    total_inventory=your_inventory,\n",
    "    method='sampling'\n",
    ")\n",
    "\n",
    "# For LSA-based agent\n",
    "clairvoyant_lsa = compute_clairvoyant_enhanced(\n",
    "    prices=your_prices,\n",
    "    environment=your_env,\n",
    "    T=your_T,\n",
    "    total_inventory=your_inventory,\n",
    "    method='lsa'\n",
    ")\n",
    "\n",
    "# Compare the two approaches\n",
    "print(f\"LP Upper Bound: {clairvoyant_lsa['total_expected_revenue_upper_bound']:.2f}\")\n",
    "print(f\"LSA Expected: {clairvoyant_lsa['lsa_expected_revenue']:.2f}\")\n",
    "print(f\"LSA vs LP Ratio: {clairvoyant_lsa['lsa_vs_lp_ratio']:.3f}\")\n",
    "print(f\"Inventory Constraint Binding: {clairvoyant_lsa['inventory_constraint_binding']}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6b7b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_combinatorial_simulation(environment, agent, T, verbose=True):\n",
    "    \"\"\"\n",
    "    Run a complete simulation of the combinatorial UCB algorithm.\n",
    "\n",
    "    Args:\n",
    "        environment: MultiProductPricingEnvironment instance\n",
    "        agent: CombinatorialUCBWithInventory instance\n",
    "        T: Number of rounds to simulate\n",
    "        verbose: Whether to print progress information\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing simulation results\n",
    "    \"\"\"\n",
    "    total_revenue = 0.0\n",
    "    total_products_sold = 0\n",
    "    revenue_per_round = []\n",
    "    cumulative_revenue = []\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"=== Running Combinatorial UCB Simulation for {T} rounds ===\")\n",
    "        print(f\"Products: {environment.n_products}\")\n",
    "        print(f\"Initial inventory: {agent.initial_inventory}\")\n",
    "        print(f\"Price options: {agent.price_options}\")\n",
    "\n",
    "    for t in range(T):\n",
    "        # Agent selects product subset and prices\n",
    "        product_subset, prices = agent.select_action()\n",
    "\n",
    "        if not product_subset:\n",
    "            # No products available (inventory exhausted)\n",
    "            revenue = 0.0\n",
    "            products_purchased = []\n",
    "        else:\n",
    "            # Convert to price array for environment\n",
    "            price_array = np.zeros(environment.n_products)\n",
    "            for i, product_idx in enumerate(product_subset):\n",
    "                price_array[product_idx] = prices[i]\n",
    "\n",
    "            # Simulate customer interaction\n",
    "            products_purchased, revenue = environment.simulate_round(price_array, product_subset)\n",
    "\n",
    "        # Update agent with outcome\n",
    "        agent.update(products_purchased, revenue)\n",
    "\n",
    "        # Track statistics\n",
    "        total_revenue += revenue\n",
    "        total_products_sold += len(products_purchased)\n",
    "        revenue_per_round.append(revenue)\n",
    "        cumulative_revenue.append(total_revenue)\n",
    "\n",
    "        # Print progress occasionally\n",
    "        if verbose and (t + 1) % (T // 10) == 0:\n",
    "            remaining_inventory = np.sum(agent.remaining_inventory)\n",
    "            print(f\"Round {t + 1:4d}: Revenue = {revenue:6.2f}, \"\n",
    "                  f\"Cumulative = {total_revenue:8.2f}, \"\n",
    "                  f\"Products sold this round = {len(products_purchased)}, \"\n",
    "                  f\"Remaining inventory = {remaining_inventory:.0f}\")\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\n=== Simulation Complete ===\")\n",
    "        print(f\"Total revenue: {total_revenue:.2f}\")\n",
    "        print(f\"Average revenue per round: {total_revenue / T:.2f}\")\n",
    "        print(f\"Total products sold: {total_products_sold}\")\n",
    "        print(f\"Remaining inventory: {agent.remaining_inventory}\")\n",
    "        print(f\"Inventory utilization: {100 * (1 - np.sum(agent.remaining_inventory) / np.sum(agent.initial_inventory)):.1f}%\")\n",
    "\n",
    "    return {\n",
    "        'total_revenue': total_revenue,\n",
    "        'revenue_per_round': revenue_per_round,\n",
    "        'cumulative_revenue': cumulative_revenue,\n",
    "        'total_products_sold': total_products_sold,\n",
    "        'final_inventory': agent.remaining_inventory,\n",
    "        'inventory_utilization': 1 - np.sum(agent.remaining_inventory) / np.sum(agent.initial_inventory),\n",
    "        'agent': agent\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6540327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_combinatorial_results(results, optimal_policy, optimal_total_revenue, T, environment, plot_titles=None, budget=None):\n",
    "    \"\"\"\n",
    "    Generate comprehensive visualizations for combinatorial UCB results based on the selected plot titles.\n",
    "    \n",
    "    Args:\n",
    "        results: Simulation results dictionary\n",
    "        optimal_policy: Theoretical optimal policy\n",
    "        optimal_total_revenue: Total optimal revenue (theoretical)\n",
    "        T: Number of rounds\n",
    "        environment: Environment instance\n",
    "        plot_titles: List of titles of the plots to display (optional)\n",
    "        budget: Optional budget parameter to update the title\n",
    "    \"\"\"\n",
    "\n",
    "    agents = {}\n",
    "\n",
    "    for agents_name, res in results.items():\n",
    "        agent = res['agent']\n",
    "        revenue_per_round = res['revenue_per_round']\n",
    "        cumulative_revenue = res['cumulative_revenue']\n",
    "\n",
    "        agents[agents_name] = {\n",
    "            'agent': agent,\n",
    "            'revenue_per_round': revenue_per_round,\n",
    "            'cumulative_revenue': cumulative_revenue\n",
    "        }\n",
    "\n",
    "    # Create subplots: Always 3 rows and 3 columns\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(20, 12))\n",
    "    \n",
    "    # Flatten axes for easier indexing\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Titles for plotting and their corresponding axes index\n",
    "    all_titles = [\"Revenue Performance\", \"Revenue Convergence\", \"Inventory Depletion\", \n",
    "                  \"Regret Growth\", \"Average Regret\", \"Average Revenue\"]\n",
    "    \n",
    "    # Ensure only the selected titles are plotted, ordered based on input list\n",
    "    if plot_titles is None:\n",
    "        plot_titles = all_titles  # Show all by default\n",
    "\n",
    "    for idx, title in enumerate(plot_titles):\n",
    "        ax = axes[idx]  # Get the corresponding subplot axis\n",
    "\n",
    "        # 1. Cumulative Revenue vs Theoretical Upper Bound\n",
    "        if title == \"Revenue Performance\":\n",
    "            optimal_upper_bound = optimal_total_revenue\n",
    "\n",
    "            for agent_name, agent_data in agents.items():\n",
    "                ax.plot(agent_data['cumulative_revenue'], label=agent_name, linewidth=3, alpha=0.8)\n",
    "\n",
    "            ax.plot([optimal_upper_bound * (t+1) / T for t in range(T)],\n",
    "                    label='Theoretical Upper Bound', linestyle='--', linewidth=2, color='black', alpha=0.6)\n",
    "\n",
    "            for agent_name, agent_data in agents.items():\n",
    "                final_performance = (np.mean(np.array(agent_data['cumulative_revenue']) /\n",
    "                                             np.array([optimal_upper_bound * (t+1) / T for t in range(T)]))) * 100\n",
    "                ax.set_title(f\"Revenue Performance: Combinatorial UCB vs Upper Bound (Budget: {budget*100:.1f}%)\")\n",
    "                ax.set_xlabel('Round')\n",
    "                ax.set_ylabel('Cumulative Revenue')\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # 2. Revenue per Round (with moving average)\n",
    "        elif title == \"Revenue Convergence\":\n",
    "            window_size = min(100, T // 20)\n",
    "            if window_size > 1:\n",
    "\n",
    "                for agent_name, agent_data in agents.items():\n",
    "                    revenue_per_round = agent_data['revenue_per_round']\n",
    "                    moving_avg = np.convolve(revenue_per_round, np.ones(window_size)/window_size, mode='valid')\n",
    "\n",
    "                    ax.plot(range(window_size-1, T), moving_avg, linewidth=3,\n",
    "                            label=f'Revenue (MA-{window_size}) - {agent_name}', color='blue', alpha=0.8)\n",
    "            else:\n",
    "                for agent_name, agent_data in agents.items():\n",
    "                    revenue_per_round = agent_data['revenue_per_round']\n",
    "                    ax.plot(revenue_per_round, linewidth=1, alpha=0.7,\n",
    "                            label=f'Revenue per Round - {agent_name}', color='blue')\n",
    "\n",
    "            avg_optimal_per_round = optimal_upper_bound / T\n",
    "            ax.axhline(avg_optimal_per_round, color='red', linestyle='--', linewidth=2,\n",
    "                       label=f'Avg Optimal ({avg_optimal_per_round:.2f})', alpha=0.8)\n",
    "\n",
    "            ax.set_title(f'Revenue Convergence Analysis (Budget: {budget*100:.1f}%)')\n",
    "            ax.set_xlabel('Round')\n",
    "            ax.set_ylabel('Revenue per Round')\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # 3. Inventory Levels Over Time\n",
    "        elif title == \"Inventory Depletion\":\n",
    "            for agent_name, agent_data in agents.items():\n",
    "                inventory_history = agent_data['inventory_history']\n",
    "                ax.plot(inventory_history, linewidth=2, alpha=0.8,\n",
    "                        label=f'Inventory - {agent_name}')\n",
    "                \n",
    "            ax.set_title(f'Inventory Depletion Over Time (Budget: {budget*100:.1f}%)')\n",
    "            ax.set_xlabel('Round')\n",
    "            ax.set_ylabel('Remaining Inventory')\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # 4. Regret Growth\n",
    "        elif title == \"Regret Growth\":\n",
    "            optimal_revenue_per_round = optimal_upper_bound / T\n",
    "            cumulative_optimal = np.array([optimal_revenue_per_round * (t+1) for t in range(T)])\n",
    "\n",
    "            for agent_name, agent_data in agents.items():\n",
    "                cumulative_revenue = agent_data['cumulative_revenue']\n",
    "                cumulative_regret = cumulative_optimal - np.array(cumulative_revenue)\n",
    "                ax.plot(cumulative_regret, linewidth=3, alpha=0.8, label=f'Cumulative Regret: {agent_name}')\n",
    "\n",
    "            t_vals = np.arange(1, T + 1)\n",
    "            theoretical_bound = 2 * np.sqrt(len(agent.price_options) * np.log(t_vals) * t_vals)\n",
    "            ax.plot(t_vals, theoretical_bound, '--', color='black', alpha=0.6, linewidth=2,\n",
    "                    label='Theoretical Bound O(√T log T)')\n",
    "\n",
    "            ax.axhline(y=0, color='black', linestyle='--', linewidth=0.5)\n",
    "\n",
    "            ax.set_title(f'Regret Growth Over Time (Budget: {budget*100:.1f}%)')\n",
    "            ax.set_xlabel('Round')\n",
    "            ax.set_ylabel('Cumulative Regret')\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # 5. Average Regret per Round\n",
    "        elif title == \"Average Regret\":\n",
    "\n",
    "            for agent_name, agent_data in agents.items():\n",
    "                cumulative_regret = agent_data['cumulative_regret']\n",
    "                avg_regret = cumulative_regret / t_vals\n",
    "                ax.plot(avg_regret, linewidth=3, color='purple', alpha=0.8, label=f'Average Regret: {agent_name}')\n",
    "                ax.axhline(y=0, color='green', linestyle='--', alpha=0.7, linewidth=2, label='Zero Regret')\n",
    "                    \n",
    "                window = min(500, T // 10)\n",
    "                if window > 1:\n",
    "                    moving_avg_regret = np.convolve(avg_regret, np.ones(window)/window, mode='valid')\n",
    "                    ax.plot(range(window-1, len(avg_regret)), moving_avg_regret,\n",
    "                            linewidth=2, alpha=0.8, color='orange', label=f'Moving Avg ({window}): {agent_name}')\n",
    "\n",
    "\n",
    "            ax.set_title(f'Average Regret Convergence (Budget: {budget*100:.1f}%)')\n",
    "            ax.set_xlabel('Round')\n",
    "            ax.set_ylabel('Average Regret per Round')\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # 6. R_T/T Analysis\n",
    "        elif title == \"Average Revenue\":\n",
    "\n",
    "            for agent_name, agent_data in agents.items():\n",
    "                cumulative_revenue = agent_data['cumulative_revenue']\n",
    "                R_T_over_T = np.array(cumulative_revenue) / (np.arange(1, T + 1))\n",
    "                ax.plot(R_T_over_T, linewidth=3, color='orange', alpha=0.8, label=f'R_T / T: {agent_name}')\n",
    "   \n",
    "            ax.axhline(y=optimal_upper_bound / T, color='red', linestyle='--', linewidth=2,\n",
    "            label='Optimal Revenue per Round', alpha=0.8)\n",
    "            ax.set_title(f'Average Revenue per Round Over Time (Budget: {budget*100:.1f}%)')\n",
    "            ax.set_xlabel('Round')\n",
    "            ax.set_ylabel('R_T / T')\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Additional Analysis: Best Strategies Summary\n",
    "    if plot_titles is None or \"Best Strategies\" in plot_titles:\n",
    "        print(\"\\n=== Learned Best Strategies per Product ===\")\n",
    "        best_strategies = agent.get_best_strategy()\n",
    "\n",
    "        for product_idx, strategy in best_strategies.items():\n",
    "            opt_info = optimal_policy['per_product_policies'][product_idx]\n",
    "            print(f\"Product {product_idx}:\")\n",
    "            price_dist_str = np.array2string(opt_info['optimal_price_distribution'], precision=2, separator=', ')\n",
    "            print(f\"  Learned best price: {strategy['best_price']:.3f} \"\n",
    "                  f\"(Optimal dist: {price_dist_str})\")\n",
    "            print(f\"  Avg revenue: {strategy['avg_revenue']:.3f} \"\n",
    "                  f\"(Optimal: {opt_info['expected_revenue_per_round']:.3f})\")\n",
    "            print(f\"  Purchase prob: {strategy['purchase_prob']:.3f} \"\n",
    "                  f\"(Optimal: {opt_info['purchase_probability']:.3f})\")\n",
    "            print(f\"  Times tried: {strategy['pulls']:.0f}\")\n",
    "            print()\n",
    "\n",
    "    return {\n",
    "        #'final_performance_pct': final_performance,\n",
    "        #'inventory_utilization': results['inventory_utilization'],\n",
    "        #'best_strategies': best_strategies\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c174541c",
   "metadata": {},
   "source": [
    "# Agent + Simulation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd30bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_experiment(agents, optimal_policy, optimal_total_revenue, T, environment, inventory_percentage, price_options, n_products, inventory):\n",
    "    \"\"\"\n",
    "    Run simulation experiment for multiple agents and analyze results.\n",
    "    \n",
    "    Args:\n",
    "        agents: Dictionary of agent instances\n",
    "        optimal_policy: Clairvoyant optimal policy\n",
    "        optimal_total_revenue: Theoretical optimal revenue\n",
    "        T: Number of rounds\n",
    "        environment: Environment instance\n",
    "        inventory_percentage: Inventory percentage used\n",
    "        price_options: Available price options\n",
    "        n_products: Number of products\n",
    "        inventory: Total inventory\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing results and analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Agents initialized with:\")\n",
    "    for agent_name, agent in agents.items():\n",
    "        print(f\"  {agent_name}:\")\n",
    "        print(f\"    Confidence bound: {agent.confidence_bound}\")\n",
    "        print(f\"    Rho penalty factor: {agent.rho_penalty}\")\n",
    "        print(f\"    Use penalty rho: {agent.use_pen_rho}\")\n",
    "        print(f\"    Products: {agent.n_products}\")\n",
    "        print(f\"    Price options per product: {len(agent.price_options)}\")\n",
    "    print(f\"  Total product-price combinations: {n_products * len(price_options)}\")\n",
    "\n",
    "    # Run simulation\n",
    "    results = {}\n",
    "    print(\"\\n=== Running Simulation ===\")\n",
    "    for agent_name, agent in agents.items(): \n",
    "        print(f\"\\n--- Running agent: {agent_name} ---\")\n",
    "        results[agent_name] = run_combinatorial_simulation(environment, agent, T, verbose=True)\n",
    "\n",
    "    # Visualize and analyze results\n",
    "    print(\"\\n=== Analyzing Results ===\")\n",
    "    analysis_results = plot_combinatorial_results(\n",
    "        results, optimal_policy, optimal_total_revenue, T, environment,\n",
    "        plot_titles=[\"Revenue Performance\", \"Regret Growth\"], budget=inventory_percentage\n",
    "    )\n",
    "\n",
    "    # Additional detailed analysis\n",
    "    print(\"\\n=== Detailed Performance Analysis ===\")\n",
    "\n",
    "    # Regret analysis\n",
    "    actual_total = {}\n",
    "    total_regret = {}\n",
    "    avg_regret_per_round = {}\n",
    "\n",
    "    for agent_name, agent in agents.items():\n",
    "        actual_total[agent_name] = results[agent_name]['total_revenue']\n",
    "        total_regret[agent_name] = optimal_total_revenue - actual_total[agent_name]\n",
    "        avg_regret_per_round[agent_name] = total_regret[agent_name] / T\n",
    "\n",
    "    for agent_name in agents.keys():\n",
    "        print(f\"\\nRegret analysis for agent: {agent_name}\")\n",
    "        print(f\"Total regret {agent_name}: {total_regret[agent_name]:.2f}\")\n",
    "        print(f\"Average regret per round {agent_name}: {avg_regret_per_round[agent_name]:.4f}\")\n",
    "        print(f\"Regret as % of optimal {agent_name}: {100 * total_regret[agent_name] / optimal_total_revenue:.2f}%\")\n",
    "\n",
    "    # Action space exploration for all agents\n",
    "    print(f\"\\nExploration statistics:\")\n",
    "    for agent_name, agent in agents.items():\n",
    "        unique_actions = set()\n",
    "        for action in agent.history['actions']:\n",
    "            product_subset, price_indices = action\n",
    "            if product_subset:  # Ignore empty actions\n",
    "                unique_actions.add(tuple(sorted(zip(product_subset, price_indices))))\n",
    "        \n",
    "        print(f\"  {agent_name} Agent:\")\n",
    "        print(f\"    Unique actions tried: {len(unique_actions)}\")\n",
    "        print(f\"    Total product-price combinations: {n_products * len(price_options)}\")\n",
    "        print(f\"    Average actions per round: {len(agent.history['actions']) / T:.2f}\")\n",
    "\n",
    "    # Revenue distribution analysis for all agents\n",
    "    print(f\"\\nRevenue statistics:\")\n",
    "    for agent_name in agents.keys():\n",
    "        revenue_per_round = np.array(results[agent_name]['revenue_per_round'])\n",
    "        print(f\"  {agent_name} Agent:\")\n",
    "        print(f\"    Mean revenue per round: {np.mean(revenue_per_round):.3f}\")\n",
    "        print(f\"    Std revenue per round: {np.std(revenue_per_round):.3f}\")\n",
    "        print(f\"    Max revenue in single round: {np.max(revenue_per_round):.3f}\")\n",
    "        print(f\"    Rounds with zero revenue: {np.sum(revenue_per_round == 0)} ({100*np.sum(revenue_per_round == 0)/T:.1f}%)\")\n",
    "\n",
    "    print(f\"\\n=== Final Summary ===\")\n",
    "    for agent_name in agents.keys():\n",
    "        performance_pct = 100 * actual_total[agent_name] / optimal_total_revenue\n",
    "        inventory_utilization = (inventory - results[agent_name]['final_inventory']) / inventory\n",
    "        print(f\"{agent_name} Agent achieved {performance_pct:.1f}% of theoretical upper bound\")\n",
    "        print(f\"{agent_name} Agent overall inventory utilization: {100*inventory_utilization:.1f}%\")\n",
    "    \n",
    "    return {\n",
    "        'results': results,\n",
    "        'analysis_results': analysis_results,\n",
    "        'actual_total': actual_total,\n",
    "        'total_regret': total_regret,\n",
    "        'avg_regret_per_round': avg_regret_per_round\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2b0597",
   "metadata": {},
   "source": [
    "# Experimental Setup and Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1332e5f4",
   "metadata": {},
   "source": [
    "# Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d861fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "T=10000\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Environment parameters\n",
    "n_products = 3  # Number of different products\n",
    "\n",
    "means = [0.6, 0.4, 0.5]  # Mean valuations for each product\n",
    "std_devs = [0.1, 0.15, 0.08]  # Standard deviations for each product\n",
    "\n",
    "D = np.diag(std_devs)\n",
    "\n",
    "rho12 = 0.3\n",
    "rho13 = 0.2\n",
    "rho23 = 0.4\n",
    "  # aumenta qui (valido finché 0<=rho<=1)\n",
    "R = np.array([[1,   rho12, rho13],\n",
    "              [rho12, 1,   rho23],\n",
    "              [rho13, rho23, 1  ]])\n",
    "cov = D @ R @ D  # matrice di covarianza PSD\n",
    "\n",
    "valuation_distributions=stats.multivariate_normal(mean=means, cov=cov)\n",
    "\n",
    "# Sample points\n",
    "samples = valuation_distributions.rvs(size=100000)\n",
    "\n",
    "# Plot pairwise projections\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 10))\n",
    "labels = ['Product 0', 'Product 1', 'Product 2']\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax = axes[i, j]\n",
    "        if i == j:\n",
    "            # Marginal histogram\n",
    "            ax.hist(samples[:, i], bins=50, density=True, alpha=0.7)\n",
    "            ax.set_xlim(-0.2, 1.05)\n",
    "            ax.set_ylim(0, 5)\n",
    "            \n",
    "            # Plot the continuous distribution (PDF) for the product\n",
    "            x_vals = np.linspace(-0.5, 1.5, 100000)\n",
    "            #pdf_vals = valuation_distributions.pdf(np.column_stack([x_vals, np.zeros_like(x_vals), np.zeros_like(x_vals)]))\n",
    "            #ax.plot(x_vals, pdf_vals, color='blue', label='PDF', linewidth=2)\n",
    "            \n",
    "            # Draw a dashed line for the mean\n",
    "            ax.axvline(means[i], color='red', linestyle='--', label=f'Mean: {means[i]:.2f}')\n",
    "            ax.legend()\n",
    "        else:\n",
    "            # Scatter for 2D projection\n",
    "            ax.scatter(samples[:, j], samples[:, i], s=1, alpha=0.3)\n",
    "            ax.set_xlim(-0.2, 1.05)\n",
    "            ax.set_ylim(-0.2, 1.05)\n",
    "            \n",
    "            # Mark the mean in the scatter plot\n",
    "            ax.scatter(means[j], means[i], color='red', s=100, marker='.', label='Mean')\n",
    "            ax.legend()\n",
    "\n",
    "        ax.set_xlabel(labels[j])\n",
    "        ax.set_ylabel(labels[i])\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"\\nProduct valuation distribution:\")\n",
    "print(f\"Means: {means}\")\n",
    "print(f\"Covariances: {cov}\")\n",
    "\n",
    "\n",
    "# Inventory constraints per product\n",
    "inventory_per_product = [int(T * 0.1), int(T * 0.05), int(T * 0.15)]  # Different inventory levels\n",
    "inventory=T*inventory_percentage*n_products  # Total inventory across all products\n",
    "\n",
    "n_prices = 4  # Number of price options per product\n",
    "# Price options (same for all products for simplicity)\n",
    "epsilon = min(inventory_per_product)**(-1/3)  # Number of price options based on epsilon\n",
    "#price_options = np.arange(0.1, 0.9, step=epsilon)  # [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "price_options = np.linspace(0.1, 0.9, n_prices+2)  # set of prices\n",
    "\n",
    "print(\"=== Experimental Setup ===\")\n",
    "print(f\"Number of products: {n_products}\")\n",
    "print(f\"Time horizon: {T} rounds\")\n",
    "print(f\"Price options: {price_options}\")\n",
    "print(f\"Initial inventory: {inventory_per_product}\")\n",
    "print(f\"Total inventory: {sum(inventory_per_product)}\")\n",
    "\n",
    "\n",
    "# Create environment\n",
    "environment = MultiProductPricingEnvironment(valuation_distributions)\n",
    "\n",
    "# Compute theoretical optimal\n",
    "print(\"\\n=== Computing Theoretical Optimal ===\")\n",
    "# optimal_policy = compute_optimal_policy(\n",
    "#     environment, price_options, inventory_per_product, T\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97756446",
   "metadata": {},
   "source": [
    "# Compute optimal for method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf2441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_optimal_for_method(method, price_options, environment, T, inventory):\n",
    "    \"\"\"\n",
    "    Compute optimal policy and revenue for a given method and inventory.\n",
    "    \n",
    "    Args:\n",
    "        method: 'sampling' or 'lsa'\n",
    "        price_options: Available price options\n",
    "        environment: Environment instance\n",
    "        T: Time horizon\n",
    "        inventory: Total inventory\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (optimal_policy, optimal_total_revenue)\n",
    "    \"\"\"\n",
    "    optimal_policy = compute_clairvoyant(price_options, environment, T, inventory, method=method)\n",
    "    optimal_total_revenue = optimal_policy['total_expected_revenue_upper_bound']\n",
    "    \n",
    "    print(f\"=== Optimal Policy ({method.upper()}) ===\")\n",
    "    print(\"Optimal single-product policies:\")\n",
    "    \n",
    "    for product_idx, policy in optimal_policy['per_product_policies'].items():\n",
    "        price_dist_str = np.array2string(policy['optimal_price_distribution'], precision=2, separator=', ')\n",
    "        print(f\"  Product {product_idx}: Price_distribution={price_dist_str}, \"\n",
    "               f\"Revenue/round={policy['expected_revenue_per_round']:.3f}\")\n",
    "    \n",
    "    print(f\"\\nUpper bound total revenue: {optimal_total_revenue:.2f}\")\n",
    "    print(f\"Upper bound avg revenue/round: {optimal_total_revenue/T:.3f}\")\n",
    "    \n",
    "    return optimal_policy, optimal_total_revenue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d94a8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_agents_by_budget_lsa(budget_percentage, T, environment, price_options, n_products):\n",
    "    \"\"\"\n",
    "    Compare UCB vs Thompson Sampling agents for a given budget percentage using LSA method.\n",
    "    \n",
    "    Args:\n",
    "        budget_percentage: Budget as percentage of T (e.g., 0.2 for 20%)\n",
    "        T: Time horizon\n",
    "        environment: Environment instance\n",
    "        price_options: Available price options\n",
    "        n_products: Number of products\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing experiment results for LSA method\n",
    "    \"\"\"\n",
    "    print(f\"=== Comparing Agents with {budget_percentage*100:.0f}% Budget (LSA Method) ===\")\n",
    "    \n",
    "    # Calculate total inventory based on budget percentage\n",
    "    inventory = T * budget_percentage * n_products\n",
    "    print(f\"Budget: {budget_percentage*100:.0f}% → Total inventory: {inventory:.0f}\")\n",
    "\n",
    "    # Initialize UCB agent with LSA-based action selection\n",
    "    agent_ucb_lsa = UCBMatchingAgent(\n",
    "        n_products=n_products,\n",
    "        price_options=price_options,\n",
    "        inventory=inventory,\n",
    "        T=T,\n",
    "        confidence_bound=1,        # Controls exploration vs exploitation\n",
    "        rho_penalty=1,            # Inventory penalty factor\n",
    "        use_pen_rho=False,        # Disable dynamic penalty adjustment\n",
    "        selection_method='lsa'    # Use Linear Sum Assignment for action selection\n",
    "    )\n",
    "\n",
    "    # Initialize Thompson Sampling agent (keeping sampling method since it doesn't support LSA)\n",
    "    agent_thompson = MultiThompsonSamplingPricingAgent(\n",
    "        price_options=price_options,\n",
    "        alpha_prior=1.0,          # Beta distribution prior (success parameter)\n",
    "        beta_prior=1.0,           # Beta distribution prior (failure parameter)\n",
    "        n_products=n_products,\n",
    "        T=T,\n",
    "        inventory=inventory,\n",
    "        rho_penalty=1.0,          # Inventory penalty factor\n",
    "        use_pen_rho=False,        # Disable dynamic penalty adjustment\n",
    "        confidence_bound=1.0      # Confidence parameter (for compatibility)\n",
    "    )\n",
    "\n",
    "    # Create agent dictionary for comparison\n",
    "    agents = {\n",
    "        'UCB_LSA': agent_ucb_lsa, \n",
    "        'Thompson': agent_thompson\n",
    "    }\n",
    "\n",
    "    # Compute theoretical optimal policy using LSA method\n",
    "    optimal_policy, optimal_total_revenue = compute_optimal_for_method(\n",
    "        'lsa', price_options, environment, T, inventory\n",
    "    )\n",
    "\n",
    "    # Run comprehensive experiment comparing both agents\n",
    "    print(f\"\\n=== Running Comparative Experiment (LSA Method) ===\")\n",
    "    print(f\"Comparing {len(agents)} agents over {T} rounds with {budget_percentage*100:.0f}% budget\")\n",
    "\n",
    "    experiment = run_experiment(\n",
    "        agents=agents,\n",
    "        optimal_policy=optimal_policy, \n",
    "        optimal_total_revenue=optimal_total_revenue,\n",
    "        T=T,\n",
    "        environment=environment,\n",
    "        inventory_percentage=budget_percentage,\n",
    "        price_options=price_options,\n",
    "        n_products=n_products,\n",
    "        inventory=inventory\n",
    "    )\n",
    "    \n",
    "    return experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387b5639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_agents_by_budget(budget_percentage, T, environment, price_options, n_products):\n",
    "    \"\"\"\n",
    "    Compare UCB vs Thompson Sampling agents for a given budget percentage.\n",
    "    \n",
    "    Args:\n",
    "        budget_percentage: Budget as percentage of T (e.g., 0.2 for 20%)\n",
    "        T: Time horizon\n",
    "        environment: Environment instance\n",
    "        price_options: Available price options\n",
    "        n_products: Number of products\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing experiment results\n",
    "    \"\"\"\n",
    "    print(f\"=== Comparing Agents with {budget_percentage*100:.0f}% Budget ===\")\n",
    "    \n",
    "    # Calculate total inventory based on budget percentage\n",
    "    inventory = T * budget_percentage * n_products\n",
    "    print(f\"Budget: {budget_percentage*100:.0f}% → Total inventory: {inventory:.0f}\")\n",
    "\n",
    "    # Initialize UCB agent with sampling-based action selection\n",
    "    agent_ucb = UCBMatchingAgent(\n",
    "        n_products=n_products,\n",
    "        price_options=price_options,\n",
    "        inventory=inventory,\n",
    "        T=T,\n",
    "        confidence_bound=1,        # Controls exploration vs exploitation\n",
    "        rho_penalty=1,            # Inventory penalty factor\n",
    "        use_pen_rho=False,        # Disable dynamic penalty adjustment\n",
    "        selection_method='sampling'  # Use probabilistic sampling for action selection\n",
    "    )\n",
    "\n",
    "    # Initialize Thompson Sampling agent\n",
    "    agent_thompson = MultiThompsonSamplingPricingAgent(\n",
    "        price_options=price_options,\n",
    "        alpha_prior=1.0,          # Beta distribution prior (success parameter)\n",
    "        beta_prior=1.0,           # Beta distribution prior (failure parameter)\n",
    "        n_products=n_products,\n",
    "        T=T,\n",
    "        inventory=inventory,\n",
    "        rho_penalty=1.0,          # Inventory penalty factor\n",
    "        use_pen_rho=False,        # Disable dynamic penalty adjustment\n",
    "        confidence_bound=1.0      # Confidence parameter (for compatibility)\n",
    "    )\n",
    "\n",
    "    # Create agent dictionary for comparison\n",
    "    agents = {\n",
    "        'UCB': agent_ucb, \n",
    "        'Thompson': agent_thompson\n",
    "    }\n",
    "\n",
    "    # Compute theoretical optimal policy using sampling method\n",
    "    optimal_policy, optimal_total_revenue = compute_optimal_for_method(\n",
    "        'sampling', price_options, environment, T, inventory\n",
    "    )\n",
    "\n",
    "    # Run comprehensive experiment comparing both agents\n",
    "    print(f\"\\n=== Running Comparative Experiment ===\")\n",
    "    print(f\"Comparing {len(agents)} agents over {T} rounds with {budget_percentage*100:.0f}% budget\")\n",
    "\n",
    "    experiment = run_experiment(\n",
    "        agents=agents,\n",
    "        optimal_policy=optimal_policy, \n",
    "        optimal_total_revenue=optimal_total_revenue,\n",
    "        T=T,\n",
    "        environment=environment,\n",
    "        inventory_percentage=budget_percentage,\n",
    "        price_options=price_options,\n",
    "        n_products=n_products,\n",
    "        inventory=inventory\n",
    "    )\n",
    "    \n",
    "    return experiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9bcdd7",
   "metadata": {},
   "source": [
    "# Low budget-> 20% of the total T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaed937",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory_percentage=0.2\n",
    "\n",
    "inventory=T*inventory_percentage*n_products  # Total inventory across all products\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbba12a",
   "metadata": {},
   "source": [
    "# Agent with 'SAMPLING' selection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb242c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_results = compare_agents_by_budget(\n",
    "    budget_percentage=inventory_percentage, \n",
    "    T=T, \n",
    "    environment=environment, \n",
    "    price_options=price_options, \n",
    "    n_products=n_products\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1688ef",
   "metadata": {},
   "source": [
    "# Agent with 'LINEAR SUM ASSIGNMENT' selection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de604505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# AGENT COMPARISON: UCB vs Thompson Sampling with LSA Method\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "# Run the LSA-based comparison\n",
    "experiment_results_lsa = compare_agents_by_budget_lsa(\n",
    "    budget_percentage=inventory_percentage, \n",
    "    T=T, \n",
    "    environment=environment, \n",
    "    price_options=price_options, \n",
    "    n_products=n_products\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e893da67",
   "metadata": {},
   "source": [
    "# Mid Budget->50%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ffb935",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory_percentage=0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c839a1",
   "metadata": {},
   "source": [
    "# Agent with 'SAMPLING' selection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a9f69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# AGENT COMPARISON: UCB vs Thompson Sampling with Sampling Method\n",
    "# =============================================================================\n",
    "\n",
    "experiment_results = compare_agents_by_budget(\n",
    "    budget_percentage=inventory_percentage, \n",
    "    T=T, \n",
    "    environment=environment, \n",
    "    price_options=price_options, \n",
    "    n_products=n_products\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce2fa06",
   "metadata": {},
   "source": [
    "# Agent with 'LINEAR SUM ASSIGNMENT' selection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001746d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# AGENT COMPARISON: UCB vs Thompson Sampling with LSA Method\n",
    "# =============================================================================\n",
    "\n",
    "experiment_results_lsa = compare_agents_by_budget_lsa(\n",
    "    budget_percentage=inventory_percentage, \n",
    "    T=T, \n",
    "    environment=environment, \n",
    "    price_options=price_options, \n",
    "    n_products=n_products\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bafe881",
   "metadata": {},
   "source": [
    "# High Budget -> 80% of the total T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc9d399",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory_percentage=0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fc94be",
   "metadata": {},
   "source": [
    "# Agent with 'SAMPLING' selection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae2c572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# AGENT COMPARISON: UCB vs Thompson Sampling with Sampling Method\n",
    "# =============================================================================\n",
    "\n",
    "experiment_results = compare_agents_by_budget(\n",
    "    budget_percentage=inventory_percentage, \n",
    "    T=T, \n",
    "    environment=environment, \n",
    "    price_options=price_options, \n",
    "    n_products=n_products\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b62a43c",
   "metadata": {},
   "source": [
    "# Agent with 'LINEAR SUM ASSIGNMENT' selection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0f74a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# AGENT COMPARISON: UCB vs Thompson Sampling with LSA Method\n",
    "# =============================================================================\n",
    "\n",
    "experiment_results_lsa = compare_agents_by_budget_lsa(\n",
    "    budget_percentage=budget, \n",
    "    T=T, \n",
    "    environment=environment, \n",
    "    price_options=price_options, \n",
    "    n_products=n_products\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
