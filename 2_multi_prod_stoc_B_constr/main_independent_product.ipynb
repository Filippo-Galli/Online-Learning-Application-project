{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e6e191e8",
      "metadata": {
        "id": "e6e191e8"
      },
      "source": [
        "# Task 2: Multi Product with B constrain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b963d8a",
      "metadata": {
        "id": "6b963d8a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm, multivariate_normal\n",
        "from scipy.optimize import linear_sum_assignment, linprog\n",
        "from scipy import optimize"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05cad716",
      "metadata": {
        "id": "05cad716"
      },
      "source": [
        "# Environment Setup\n",
        "\n",
        "In this notebook, we implement a Combinatorial UCB algorithm for multi-product pricing with inventory constraints.\n",
        "\n",
        "The scenario involves:\n",
        "- Multiple products with different customer valuation distributions\n",
        "- Limited inventory for each product\n",
        "- Combinatorial action space where we select a subset of products to offer\n",
        "- Goal: Maximize revenue while respecting inventory constraints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab0db09e",
      "metadata": {
        "id": "ab0db09e"
      },
      "outputs": [],
      "source": [
        "class MultiProductPricingEnvironment:\n",
        "    \"\"\"\n",
        "    Multi-product stochastic environment for dynamic pricing with inventory constraints.\n",
        "\n",
        "    This environment simulates a multi-product pricing scenario where:\n",
        "    - Each product has its own customer valuation distribution\n",
        "    - Customers have different preferences for different products\n",
        "    - Each round represents one customer interaction\n",
        "    - The customer can purchase multiple products or none at all\n",
        "    \"\"\"\n",
        "    def __init__(self, valuation_distributions, correlation_matrix=None):\n",
        "        \"\"\"\n",
        "        Initialize the multi-product pricing environment.\n",
        "\n",
        "        Args:\n",
        "            valuation_distributions: List of scipy.stats distributions for each product\n",
        "            correlation_matrix: Optional correlation matrix for product valuations\n",
        "        \"\"\"\n",
        "        self.valuation_dists = valuation_distributions\n",
        "        self.n_products = len(valuation_distributions)\n",
        "        self.correlation_matrix = correlation_matrix\n",
        "\n",
        "        # If no correlation matrix provided, assume independence\n",
        "        if correlation_matrix is None:\n",
        "            self.correlation_matrix = np.eye(self.n_products)\n",
        "\n",
        "    def demand_probability(self, prices, product_subset):\n",
        "        \"\"\"\n",
        "        Calculate the theoretical probability that a customer purchases\n",
        "        the given subset of products at given prices.\n",
        "\n",
        "        Args:\n",
        "            prices: Array of prices for each product\n",
        "            product_subset: List of product indices being offered\n",
        "\n",
        "        Returns:\n",
        "            Probability that customer will purchase this product subset\n",
        "        \"\"\"\n",
        "        if len(product_subset) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        # For simplicity, assume independent purchase decisions\n",
        "        # In practice, this could be more complex with substitution effects\n",
        "        prob = 1.0\n",
        "        for product_idx in product_subset:\n",
        "            # Probability that customer values this product >= its price\n",
        "            product_prob = 1 - self.valuation_dists[product_idx].cdf(prices[product_idx])\n",
        "            prob *= product_prob\n",
        "\n",
        "        return prob\n",
        "\n",
        "    def simulate_round(self, prices, product_subset):\n",
        "        \"\"\"\n",
        "        Simulate one customer interaction for a given product subset and prices.\n",
        "\n",
        "        Args:\n",
        "            prices: Array of prices for each product\n",
        "            product_subset: List of product indices being offered\n",
        "\n",
        "        Returns:\n",
        "            tuple: (products_purchased, total_revenue) where:\n",
        "                - products_purchased: List of products actually purchased\n",
        "                - total_revenue: Sum of revenues from purchased products\n",
        "        \"\"\"\n",
        "        if len(product_subset) == 0:\n",
        "            return [], 0.0\n",
        "\n",
        "        products_purchased = []\n",
        "        total_revenue = 0.0\n",
        "\n",
        "        # Generate customer valuations for all products\n",
        "        valuations = np.array([dist.rvs() for dist in self.valuation_dists])\n",
        "\n",
        "        # Customer purchases products where valuation >= price\n",
        "        for product_idx in product_subset:\n",
        "            if valuations[product_idx] >= prices[product_idx]:\n",
        "                products_purchased.append(product_idx)\n",
        "                total_revenue += prices[product_idx]\n",
        "\n",
        "        return products_purchased, total_revenue"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d781b8f",
      "metadata": {
        "id": "4d781b8f"
      },
      "source": [
        "# Combinatorial UCB Agent with LP-based Inventory Constraints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f1fee04",
      "metadata": {
        "id": "5f1fee04"
      },
      "outputs": [],
      "source": [
        "class CombinatorialUCBWithInventory:\n",
        "    \"\"\"\n",
        "    Combinatorial UCB agent for multi-product pricing with inventory constraints.\n",
        "\n",
        "    This agent implements a combinatorial bandit approach where:\n",
        "    1. Actions are product-price combinations for each product\n",
        "    2. Each product has limited inventory\n",
        "    3. UCB confidence bounds guide exploration vs exploitation\n",
        "    4. Linear programming optimizes the product-price selection considering inventory constraints\n",
        "    5. Uses LP-based action selection similar to single-product UCB but extended to multiple products\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_products, price_options, inventory_per_product, T,\n",
        "                 confidence_bound=1.0, rho_penalty=1.0, use_pen_rho=True):\n",
        "        \"\"\"\n",
        "        Initialize the combinatorial UCB agent with LP-based action selection.\n",
        "\n",
        "        Args:\n",
        "            n_products: Number of products\n",
        "            price_options: List of possible prices for each product\n",
        "            inventory_per_product: Initial inventory for each product\n",
        "            T: Time horizon (number of rounds)\n",
        "            confidence_bound: UCB confidence parameter\n",
        "            rho_penalty: Penalty factor for inventory constraint (>1 = more conservative)\n",
        "            use_pen_rho: Whether to use penalty factor for inventory constraints\n",
        "        \"\"\"\n",
        "        self.n_products = n_products\n",
        "        self.price_options = np.array(price_options)\n",
        "        self.T = T\n",
        "        self.confidence_bound = confidence_bound\n",
        "        self.rho_penalty = rho_penalty\n",
        "        self.use_pen_rho = use_pen_rho\n",
        "\n",
        "        # Inventory management\n",
        "        self.initial_inventory = np.array(inventory_per_product, dtype=float)\n",
        "        self.remaining_inventory = np.array(inventory_per_product, dtype=float)\n",
        "\n",
        "        # Target selling rates for each product\n",
        "        self.rho = self.initial_inventory / T  # Target selling rate per product\n",
        "\n",
        "        # Statistics for each (product, price) combination\n",
        "        self.n_price_options = len(price_options)\n",
        "        self.avg_revenue = np.zeros((n_products, self.n_price_options))\n",
        "        self.avg_purchase_prob = np.zeros((n_products, self.n_price_options))\n",
        "        self.n_pulls = np.zeros((n_products, self.n_price_options))\n",
        "\n",
        "        # Current state\n",
        "        self.t = 0\n",
        "        self.current_action_indices = None  # price indices for each product\n",
        "\n",
        "        # History tracking\n",
        "        self.history = {\n",
        "            'actions': [],\n",
        "            'revenues': [],\n",
        "            'purchases': [],\n",
        "            'inventory_levels': [],\n",
        "            'price_distributions': []  # Store computed price distributions\n",
        "        }\n",
        "\n",
        "    def select_action(self):\n",
        "        \"\"\"\n",
        "        Select actions for each product using LP-based UCB with inventory constraints.\n",
        "\n",
        "        For each product with remaining inventory:\n",
        "        1. Compute UCB bounds on revenue and LCB bounds on purchase probability\n",
        "        2. Solve LP to get optimal price distribution for that product\n",
        "        3. Sample price according to the distribution\n",
        "\n",
        "        Returns:\n",
        "            tuple: (product_subset, prices) where:\n",
        "                - product_subset: List of product indices with inventory\n",
        "                - prices: List of selected prices for each product\n",
        "        \"\"\"\n",
        "        product_subset = []\n",
        "        prices = []\n",
        "        action_map = {}  # Maps product_idx to price_idx\n",
        "\n",
        "        # Process each product independently\n",
        "        for product_idx in range(self.n_products):\n",
        "            if self.remaining_inventory[product_idx] < 1:\n",
        "                continue  # Skip products with no inventory\n",
        "\n",
        "            # Select price for this product using LP\n",
        "            price_idx = self._select_price_for_product(product_idx)\n",
        "\n",
        "            if price_idx is not None:\n",
        "                product_subset.append(product_idx)\n",
        "                prices.append(self.price_options[price_idx])\n",
        "                action_map[product_idx] = price_idx\n",
        "\n",
        "        # Store current action for update\n",
        "        self.current_action_map = action_map\n",
        "\n",
        "        return product_subset, prices\n",
        "\n",
        "    def _select_price_for_product(self, product_idx):\n",
        "        \"\"\"\n",
        "        Select price for a single product using LP-based UCB approach.\n",
        "\n",
        "        Args:\n",
        "            product_idx: Index of the product\n",
        "\n",
        "        Returns:\n",
        "            Selected price index, or None if no valid price\n",
        "        \"\"\"\n",
        "        # Exploration phase: try each price at least once\n",
        "        if self.t < self.n_price_options * self.n_products:\n",
        "            # Round-robin exploration across all product-price combinations\n",
        "            exploration_idx = self.t % (self.n_price_options * self.n_products)\n",
        "            target_product = exploration_idx // self.n_price_options\n",
        "            target_price = exploration_idx % self.n_price_options\n",
        "\n",
        "            if target_product == product_idx:\n",
        "                return target_price\n",
        "            else:\n",
        "                # If not this product's turn, select based on current knowledge\n",
        "                if np.sum(self.n_pulls[product_idx, :]) == 0:\n",
        "                    return 0  # Select first price if never tried\n",
        "                else:\n",
        "                    return np.argmax(self.avg_revenue[product_idx, :])\n",
        "\n",
        "        # LP-based exploitation phase\n",
        "        # Compute UCB bounds on revenue\n",
        "        confidence_radius = self.confidence_bound * np.sqrt(\n",
        "            2 * np.log(max(1, self.t)) / np.maximum(self.n_pulls[product_idx, :], 1)\n",
        "        )\n",
        "        f_ucbs = self.avg_revenue[product_idx, :] + confidence_radius\n",
        "\n",
        "        # Compute LCB bounds on purchase probability\n",
        "        demand_confidence_radius = self.confidence_bound * np.sqrt(\n",
        "            2 * np.log(max(1, self.t)) / np.maximum(self.n_pulls[product_idx, :], 1)\n",
        "        )\n",
        "        c_lcbs = np.maximum(0, self.avg_purchase_prob[product_idx, :] - demand_confidence_radius)\n",
        "\n",
        "        # Solve LP to get optimal price distribution for this product\n",
        "        gamma_t = self._compute_optimal_distribution(product_idx, f_ucbs, c_lcbs)\n",
        "\n",
        "        # Sample price according to computed distribution\n",
        "        price_idx = np.random.choice(self.n_price_options, p=gamma_t)\n",
        "\n",
        "        return price_idx\n",
        "\n",
        "    def _compute_optimal_distribution(self, product_idx, f_ucbs, c_lcbs):\n",
        "        \"\"\"\n",
        "        Solve LP to find optimal price distribution for a single product with inventory constraints.\n",
        "\n",
        "        Formulation for product k:\n",
        "        maximize: sum_i gamma_i * f_ucb_i (expected revenue for product k)\n",
        "        subject to: sum_i gamma_i * c_lcb_i <= current_rho_k (inventory constraint for product k)\n",
        "                   sum_i gamma_i = 1 (probability constraint)\n",
        "                   gamma_i >= 0 (non-negativity)\n",
        "\n",
        "        Args:\n",
        "            product_idx: Index of the product\n",
        "            f_ucbs: Upper confidence bounds on revenue for each price\n",
        "            c_lcbs: Lower confidence bounds on purchase probability for each price\n",
        "\n",
        "        Returns:\n",
        "            gamma: Probability distribution over prices for this product\n",
        "        \"\"\"\n",
        "        # Handle edge case: if no positive demand expected, choose highest revenue price\n",
        "        if np.all(c_lcbs <= 1e-10):\n",
        "            gamma = np.zeros(len(f_ucbs))\n",
        "            gamma[np.argmax(f_ucbs)] = 1.0\n",
        "            return gamma\n",
        "\n",
        "        # Convert to minimization problem (negate revenues)\n",
        "        c = -f_ucbs\n",
        "\n",
        "        # Compute current required selling rate for this product\n",
        "        remaining_rounds = max(1, self.T - self.t)\n",
        "        current_rho = max(self.remaining_inventory[product_idx] / remaining_rounds, 0)\n",
        "\n",
        "        # Linear program constraints\n",
        "        A_ub = [c_lcbs]  # Inventory constraint coefficients\n",
        "\n",
        "        if self.use_pen_rho:\n",
        "            # Apply penalty to make constraint more conservative\n",
        "            inventory_ratio = self.remaining_inventory[product_idx] / self.initial_inventory[product_idx]\n",
        "            time_ratio = (self.T - self.t) / self.T\n",
        "\n",
        "            if inventory_ratio > 0.5 and time_ratio > 0.5:\n",
        "                # Early stages with plenty of inventory: relax constraint\n",
        "                penalty_factor = self.rho_penalty * 1.5\n",
        "            elif inventory_ratio < 0.1:\n",
        "                # Low inventory: tighten constraint\n",
        "                penalty_factor = self.rho_penalty * 0.5\n",
        "            else:\n",
        "                penalty_factor = self.rho_penalty\n",
        "\n",
        "            penalized_rho = current_rho * penalty_factor\n",
        "\n",
        "            # If the constraint is too tight, relax it\n",
        "            min_demand = np.min(c_lcbs[c_lcbs > 0]) if np.any(c_lcbs > 0) else 0\n",
        "            if penalized_rho < min_demand * 0.5:\n",
        "                penalized_rho = min_demand * 0.8\n",
        "\n",
        "            b_ub = [penalized_rho]\n",
        "        else:\n",
        "            b_ub = [current_rho]\n",
        "\n",
        "        A_eq = [np.ones(self.n_price_options)]  # Probability constraint coefficients\n",
        "        b_eq = [1]  # Probability constraint bound\n",
        "\n",
        "        # Solve linear program\n",
        "        try:\n",
        "            res = optimize.linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq,\n",
        "                                 bounds=[(0, 1) for _ in range(self.n_price_options)], method='highs')\n",
        "            if res.success:\n",
        "                gamma = res.x\n",
        "                # Ensure valid probability distribution\n",
        "                gamma = np.maximum(gamma, 0)\n",
        "                gamma = gamma / np.sum(gamma) if np.sum(gamma) > 0 else np.ones(self.n_price_options) / self.n_price_options\n",
        "                return gamma\n",
        "            else:\n",
        "                # Fallback: uniform distribution\n",
        "                return np.ones(self.n_price_options) / self.n_price_options\n",
        "        except:\n",
        "            # Fallback: uniform distribution\n",
        "            return np.ones(self.n_price_options) / self.n_price_options\n",
        "\n",
        "    def update(self, products_purchased, total_revenue):\n",
        "        \"\"\"\n",
        "        Update agent statistics based on observed outcome.\n",
        "\n",
        "        Args:\n",
        "            products_purchased: List of products actually purchased\n",
        "            total_revenue: Total revenue obtained\n",
        "        \"\"\"\n",
        "        if not hasattr(self, 'current_action_map') or not self.current_action_map:\n",
        "            return\n",
        "\n",
        "        # Update statistics for each product that was offered\n",
        "        for product_idx, price_idx in self.current_action_map.items():\n",
        "            # Update pull count\n",
        "            self.n_pulls[product_idx, price_idx] += 1\n",
        "\n",
        "            # Determine if this specific product was purchased\n",
        "            was_purchased = product_idx in products_purchased\n",
        "            price = self.price_options[price_idx]\n",
        "            revenue_from_product = price if was_purchased else 0.0\n",
        "\n",
        "            # Update average revenue using incremental mean\n",
        "            self.avg_revenue[product_idx, price_idx] += (\n",
        "                revenue_from_product - self.avg_revenue[product_idx, price_idx]\n",
        "            ) / self.n_pulls[product_idx, price_idx]\n",
        "\n",
        "            # Update average purchase probability\n",
        "            purchase_indicator = 1.0 if was_purchased else 0.0\n",
        "            self.avg_purchase_prob[product_idx, price_idx] += (\n",
        "                purchase_indicator - self.avg_purchase_prob[product_idx, price_idx]\n",
        "            ) / self.n_pulls[product_idx, price_idx]\n",
        "\n",
        "            # Update inventory if product was purchased\n",
        "            if was_purchased and self.remaining_inventory[product_idx] > 0:\n",
        "                self.remaining_inventory[product_idx] -= 1\n",
        "\n",
        "        # Record history\n",
        "        product_subset = list(self.current_action_map.keys())\n",
        "        price_indices = list(self.current_action_map.values())\n",
        "\n",
        "        self.history['actions'].append((product_subset.copy(), price_indices.copy()))\n",
        "        self.history['revenues'].append(total_revenue)\n",
        "        self.history['purchases'].append(products_purchased.copy())\n",
        "        self.history['inventory_levels'].append(self.remaining_inventory.copy())\n",
        "\n",
        "        # Increment time\n",
        "        self.t += 1\n",
        "\n",
        "    def get_best_strategy(self):\n",
        "        \"\"\"\n",
        "        Return the best strategy learned so far for each product.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with best price and performance for each product\n",
        "        \"\"\"\n",
        "        best_strategies = {}\n",
        "\n",
        "        for product_idx in range(self.n_products):\n",
        "            best_price_idx = np.argmax(self.avg_revenue[product_idx, :])\n",
        "            best_price = self.price_options[best_price_idx]\n",
        "            best_revenue = self.avg_revenue[product_idx, best_price_idx]\n",
        "            best_prob = self.avg_purchase_prob[product_idx, best_price_idx]\n",
        "\n",
        "            best_strategies[product_idx] = {\n",
        "                'best_price': best_price,\n",
        "                'avg_revenue': best_revenue,\n",
        "                'purchase_prob': best_prob,\n",
        "                'pulls': self.n_pulls[product_idx, best_price_idx]\n",
        "            }\n",
        "    \n",
        "        return best_strategies"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cafc7c01",
      "metadata": {},
      "source": [
        "# Combinatorial UCB Agent with LP-based method and a unique Inventory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02c1b4f7",
      "metadata": {
        "id": "02c1b4f7"
      },
      "outputs": [],
      "source": [
        "# We assume that every agent can complete every task (all edges exist)\n",
        "class UCBMatchingAgent:\n",
        "\n",
        "\n",
        "    def __init__(self, n_products, price_options, inventory, T,\n",
        "                 confidence_bound=1.0, rho_penalty=1.0, use_pen_rho=True, selection_method='sampling'):\n",
        "\n",
        "        self.price_options=price_options\n",
        "        self.n_products = n_products\n",
        "        self.n_price_options=len(price_options)\n",
        "        self.W_avg = np.zeros((n_products,self.n_price_options))\n",
        "        self.N_pulls = np.zeros((n_products,self.n_price_options))\n",
        "\n",
        "        self.T = T # not strictly necessary, you can use the anytime version of UCB\n",
        "        self.t = 0\n",
        "\n",
        "        # Inventory is now a single value representing total inventory\n",
        "        self.initial_inventory = inventory\n",
        "        self.remaining_inventory = inventory\n",
        "\n",
        "        self.rho = self.initial_inventory / self.T\n",
        "\n",
        "        self.confidence_bound = confidence_bound\n",
        "        self.rho_penalty = rho_penalty\n",
        "        self.use_pen_rho = use_pen_rho\n",
        "\n",
        "        self.A_t = None\n",
        "        self.rows_t = None\n",
        "        self.cols_t = None\n",
        "\n",
        "        self.selection_method = selection_method\n",
        "\n",
        "        self.avg_revenue = np.zeros((n_products, self.n_price_options))\n",
        "        self.avg_purchase_prob = np.zeros((n_products, self.n_price_options))\n",
        "\n",
        "        # Current state\n",
        "        self.current_action_indices_map = {}  # Maps product_idx to price_idx for offered products\n",
        "\n",
        "        # History tracking\n",
        "        self.history = {\n",
        "            'actions': [], # Stores (product_subset, price_indices)\n",
        "            'revenues': [],\n",
        "            'purchases': [],\n",
        "            'inventory_levels': [], # This will now store a single value per round\n",
        "            'price_distributions': []  # Store computed price distributions\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "    def select_action(self):\n",
        "        \"\"\"\n",
        "        Select actions for each product using LP-based UCB with shared inventory constraints.\n",
        "\n",
        "        1. Compute UCB bounds on revenue and LCB bounds on purchase probability.\n",
        "        2. Solve LP to get optimal price distribution for all products considering shared inventory.\n",
        "        3. Sample prices for each product according to the distribution.\n",
        "\n",
        "        Returns:\n",
        "            tuple: (product_subset, prices) where:\n",
        "                - product_subset: List of product indices with inventory\n",
        "                - prices: List of selected prices for each product\n",
        "        \"\"\"\n",
        "\n",
        "        # If no inventory remaining, return empty action\n",
        "        if self.remaining_inventory < 1:\n",
        "            self.current_action_indices_map = {}\n",
        "            return [], []\n",
        "\n",
        "        # if an arm is unexplored, then the UCB is a large value\n",
        "        W = np.zeros(self.W_avg.shape, dtype=float)\n",
        "        C = np.zeros(self.avg_purchase_prob.shape, dtype=float)\n",
        "\n",
        "        large_value = 1e7\n",
        "        small_value = 1e-7\n",
        "\n",
        "        W[self.N_pulls==0] = large_value\n",
        "        C[self.N_pulls==0] = small_value\n",
        "\n",
        "        mask = self.N_pulls>0\n",
        "\n",
        "        sigma = self.confidence_bound * np.sqrt(2*np.log(max(1, self.t))/self.N_pulls[mask])\n",
        "\n",
        "        W[mask] = self.W_avg[mask] + sigma\n",
        "        C[mask] = np.maximum(self.avg_purchase_prob[mask] - sigma,0)\n",
        "\n",
        "        Gamma = self.compute_opt(W, C)\n",
        "        product_subset = []\n",
        "        prices = []\n",
        "        self.current_action_indices_map = {} # Reset for this round\n",
        "\n",
        "        # NEW: Use Linear Sum Assignment to select prices\n",
        "        #selected_price_indices = self._select_prices_lsa(Gamma, W)\n",
        "        \n",
        "        # Option 2: Use original sampling\n",
        "        # selected_price_indices = self._select_prices_sampling(Gamma)\n",
        "        \n",
        "        # Option 3: Use hybrid approach\n",
        "        # selected_price_indices = self._select_prices_hybrid(Gamma, W, explore_prob=0.1)\n",
        "        \n",
        "        # Option 4: Use unified method switcher\n",
        "        selected_price_indices = self._select_prices(Gamma, W, method=self.selection_method)\n",
        "\n",
        "        # Build the action using LSA-selected price indices\n",
        "        for product_idx in range(self.n_products):\n",
        "            price_idx = selected_price_indices[product_idx]\n",
        "            \n",
        "            # Add to action (all products are offered as long as total inventory > 0)\n",
        "            product_subset.append(product_idx)\n",
        "            prices.append(self.price_options[price_idx])\n",
        "            self.current_action_indices_map[product_idx] = price_idx\n",
        "\n",
        "        return product_subset, prices\n",
        "\n",
        "    def _select_prices_lsa(self, Gamma, W):\n",
        "        \"\"\"\n",
        "        Use Linear Sum Assignment to select optimal price for each product\n",
        "        based on gamma-weighted revenues.\n",
        "        \n",
        "        Args:\n",
        "            Gamma: Optimal probability distribution matrix (n_products x n_price_options)\n",
        "            W: Upper confidence bounds on revenue (n_products x n_price_options)\n",
        "        \n",
        "        Returns:\n",
        "            selected_price_indices: List of price indices for each product\n",
        "        \"\"\"\n",
        "        # Create cost matrix: gamma-weighted revenues\n",
        "        # Negative because LSA minimizes but we want to maximize revenue\n",
        "        cost_matrix = -(Gamma * W)  # Element-wise multiplication\n",
        "        \n",
        "        # Solve assignment problem\n",
        "        row_indices, col_indices = linear_sum_assignment(cost_matrix)\n",
        "        \n",
        "        return col_indices.tolist()\n",
        "\n",
        "    # Alternative implementation with exploration probability\n",
        "    def _select_prices_hybrid(self, Gamma, W, explore_prob=0.1):\n",
        "        \"\"\"\n",
        "        Hybrid approach: use LSA with probability (1-explore_prob), \n",
        "        sampling with probability explore_prob.\n",
        "        \n",
        "        Args:\n",
        "            Gamma: Optimal probability distribution matrix (n_products x n_price_options)\n",
        "            W: Upper confidence bounds on revenue (n_products x n_price_options)\n",
        "            explore_prob: Probability of using sampling instead of LSA\n",
        "        \n",
        "        Returns:\n",
        "            selected_price_indices: List of price indices for each product\n",
        "        \"\"\"\n",
        "        if np.random.random() < explore_prob:\n",
        "            # Exploration: use original sampling approach\n",
        "            selected_price_indices = []\n",
        "            for product_idx in range(self.n_products):\n",
        "                prob_dist = Gamma[product_idx, :]\n",
        "                sum_prob = np.sum(prob_dist)\n",
        "                if sum_prob > 0:\n",
        "                    prob_dist /= sum_prob\n",
        "                else:\n",
        "                    prob_dist = np.ones(self.n_price_options) / self.n_price_options\n",
        "                \n",
        "                price_idx = np.random.choice(self.n_price_options, p=prob_dist)\n",
        "                selected_price_indices.append(price_idx)\n",
        "            \n",
        "            return selected_price_indices\n",
        "        else:\n",
        "            # Exploitation: use LSA\n",
        "            return self._select_prices_lsa(Gamma, W)\n",
        "    \n",
        "        \n",
        "    def _select_prices_sampling(self, Gamma):\n",
        "        \"\"\"\n",
        "        Original sampling approach: sample price for each product according to gamma distribution.\n",
        "        \n",
        "        Args:\n",
        "            Gamma: Optimal probability distribution matrix (n_products x n_price_options)\n",
        "        \n",
        "        Returns:\n",
        "            selected_price_indices: List of price indices for each product\n",
        "        \"\"\"\n",
        "        selected_price_indices = []\n",
        "        \n",
        "        for product_idx in range(self.n_products):\n",
        "            # Ensure the distribution sums to 1 for sampling\n",
        "            prob_dist = Gamma[product_idx, :]\n",
        "            sum_prob = np.sum(prob_dist)\n",
        "            if sum_prob > 0:\n",
        "                prob_dist /= sum_prob\n",
        "            else:\n",
        "                prob_dist = np.ones(self.n_price_options) / self.n_price_options  # Fallback uniform\n",
        "            \n",
        "            price_idx = np.random.choice(self.n_price_options, p=prob_dist)\n",
        "            selected_price_indices.append(price_idx)\n",
        "        \n",
        "        return selected_price_indices\n",
        "    \n",
        "    # Method switcher for easy comparison\n",
        "    def _select_prices(self, Gamma, W, method='lsa'):\n",
        "        \"\"\"\n",
        "        Unified method to select prices using different strategies.\n",
        "        \n",
        "        Args:\n",
        "            Gamma: Optimal probability distribution matrix (n_products x n_price_options)\n",
        "            W: Upper confidence bounds on revenue (n_products x n_price_options)\n",
        "            method: Selection method ('lsa', 'sampling', 'hybrid')\n",
        "        \n",
        "        Returns:\n",
        "            selected_price_indices: List of price indices for each product\n",
        "        \"\"\"\n",
        "        if method == 'lsa':\n",
        "            return self._select_prices_lsa(Gamma, W)\n",
        "        elif method == 'sampling':\n",
        "            return self._select_prices_sampling(Gamma)\n",
        "        elif method == 'hybrid':\n",
        "            return self._select_prices_hybrid(Gamma, W, explore_prob=0.1)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown method: {method}. Use 'lsa', 'sampling', or 'hybrid'\")\n",
        "\n",
        "    def compute_opt(self, W, C):\n",
        "        \"\"\"\n",
        "        Solve LP to find optimal price distribution for multiple products with shared inventory constraints.\n",
        "\n",
        "        Formulation:\n",
        "        maximize: sum_(k,i) gamma_(k,i) * W_(k,i) (total expected revenue)\n",
        "        subject to: sum_i gamma_(k,i) = 1 for each product k (probability constraint per product)\n",
        "                   sum_(k,i) gamma_(k,i) * C_(k,i) <= current_rho_total (shared inventory constraint)\n",
        "                   gamma_(k,i) >= 0 (non-negativity)\n",
        "\n",
        "        Args:\n",
        "            W: Upper confidence bounds on revenue for each (product, price) combination (n_products x n_price_options)\n",
        "            C: Lower confidence bounds on purchase probability for each (product, price) combination (n_products x n_price_options)\n",
        "\n",
        "        Returns:\n",
        "            gamma: Probability distribution over prices for each product (n_products x n_price_options)\n",
        "        \"\"\"\n",
        "\n",
        "        # Number of variables is n_products * n_price_options\n",
        "        num_vars = self.n_products * self.n_price_options\n",
        "\n",
        "        # Flatten W and C for LP\n",
        "        c = -W.flatten()\n",
        "\n",
        "        # Compute current required selling rate for the shared inventory\n",
        "        remaining_rounds = max(1, self.T - self.t)\n",
        "        current_rho_total = max(self.remaining_inventory / remaining_rounds, 0)\n",
        "\n",
        "        # Inequality constraints (shared inventory)\n",
        "        A_ub = [C.flatten()]\n",
        "        b_ub = [current_rho_total]\n",
        "\n",
        "        # Equality constraints (probability distribution for each product)\n",
        "        A_eq = np.zeros((self.n_products, num_vars))\n",
        "        b_eq = np.ones(self.n_products)\n",
        "\n",
        "        for product_idx in range(self.n_products):\n",
        "            start_idx = product_idx * self.n_price_options\n",
        "            end_idx = start_idx + self.n_price_options\n",
        "            A_eq[product_idx, start_idx:end_idx] = 1\n",
        "\n",
        "        # Bounds for each variable (gamma_ki between 0 and 1)\n",
        "        bounds = [(0, 1) for _ in range(num_vars)]\n",
        "\n",
        "        # Solve linear program\n",
        "        try:\n",
        "            res = optimize.linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq,\n",
        "                                 bounds=bounds, method='highs')\n",
        "\n",
        "            if res.success:\n",
        "                gamma_flat = res.x\n",
        "                # Reshape gamma back to (n_products, n_price_options)\n",
        "                gamma = gamma_flat.reshape((self.n_products, self.n_price_options))\n",
        "\n",
        "                # Ensure valid probability distribution for each product\n",
        "                for product_idx in range(self.n_products):\n",
        "                    gamma[product_idx, :] = np.maximum(gamma[product_idx, :], 0)\n",
        "                    sum_gamma = np.sum(gamma[product_idx, :])\n",
        "                    if sum_gamma > 0:\n",
        "                         gamma[product_idx, :] /= sum_gamma\n",
        "                    else:\n",
        "                         # Fallback: uniform distribution for this product\n",
        "                         gamma[product_idx, :] = np.ones(self.n_price_options) / self.n_price_options\n",
        "\n",
        "                return gamma\n",
        "            else:\n",
        "                # Fallback: uniform distribution for all products\n",
        "                return np.ones((self.n_products, self.n_price_options)) / self.n_price_options\n",
        "        except Exception as e:\n",
        "            print(f\"LP Error: {e}\")\n",
        "            # Fallback: uniform distribution for all products\n",
        "            return np.ones((self.n_products, self.n_price_options)) / self.n_price_options\n",
        "\n",
        "\n",
        "    def update(self, products_purchased, total_revenue):\n",
        "        \"\"\"\n",
        "        Update agent statistics based on observed outcome.\n",
        "\n",
        "        Args:\n",
        "            products_purchased: List of products actually purchased in this round\n",
        "            total_revenue: Total revenue obtained in this round\n",
        "        \"\"\"\n",
        "        if not self.current_action_indices_map:\n",
        "            return\n",
        "\n",
        "        # Update statistics for each product that was offered (all products are offered if total inventory > 0)\n",
        "        # Iterate through the products that were *offered* in this round\n",
        "        for product_idx, price_idx in self.current_action_indices_map.items():\n",
        "\n",
        "            # Update pull count for this product-price arm\n",
        "            self.N_pulls[product_idx, price_idx] += 1\n",
        "\n",
        "            # Determine if this specific product was purchased in this round\n",
        "            was_purchased = product_idx in products_purchased\n",
        "            price = price_options[price_idx] # Assuming price_options is globally accessible or passed\n",
        "\n",
        "            # Update average revenue for this product-price arm\n",
        "            # Revenue contribution is the price if purchased, 0 otherwise\n",
        "            revenue_contribution = price if was_purchased else 0.0\n",
        "            self.W_avg[product_idx, price_idx] += (\n",
        "                revenue_contribution - self.W_avg[product_idx, price_idx]\n",
        "            ) / self.N_pulls[product_idx, price_idx]\n",
        "\n",
        "            # Update average purchase probability for this product-price arm\n",
        "            purchase_indicator = 1.0 if was_purchased else 0.0\n",
        "            self.avg_purchase_prob[product_idx, price_idx] += (\n",
        "                purchase_indicator - self.avg_purchase_prob[product_idx, price_idx]\n",
        "            ) / self.N_pulls[product_idx, price_idx]\n",
        "\n",
        "        # Update total remaining inventory based on the number of products purchased in this round\n",
        "        num_purchased_this_round = len(products_purchased)\n",
        "        if self.remaining_inventory > 0:\n",
        "            self.remaining_inventory -= num_purchased_this_round\n",
        "            self.remaining_inventory = max(0, self.remaining_inventory) # Ensure inventory doesn't go below zero\n",
        "\n",
        "\n",
        "        # Record history\n",
        "        # Store the sampled action (product_subset and price indices)\n",
        "        product_subset = list(self.current_action_indices_map.keys())\n",
        "        price_indices = list(self.current_action_indices_map.values())\n",
        "        self.history['actions'].append((product_subset.copy(), price_indices.copy()))\n",
        "\n",
        "        self.history['revenues'].append(total_revenue)\n",
        "        self.history['purchases'].append(products_purchased.copy())\n",
        "        self.history['inventory_levels'].append(self.remaining_inventory) # Store the single inventory value\n",
        "\n",
        "        # Increment time\n",
        "        self.t += 1\n",
        "\n",
        "    def get_best_strategy(self):\n",
        "        \"\"\"\n",
        "        Return the best strategy learned so far for each product based on average revenue.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with best price and performance for each product\n",
        "        \"\"\"\n",
        "        best_strategies = {}\n",
        "\n",
        "        for product_idx in range(self.n_products):\n",
        "            # Find the price index with the highest average revenue for this product\n",
        "            best_price_idx = np.argmax(self.W_avg[product_idx, :])\n",
        "            best_price = price_options[best_price_idx] # Assuming price_options is globally accessible\n",
        "            best_revenue = self.W_avg[product_idx, best_price_idx]\n",
        "            best_prob = self.avg_purchase_prob[product_idx, best_price_idx]\n",
        "\n",
        "            best_strategies[product_idx] = {\n",
        "                'best_price': best_price,\n",
        "                'avg_revenue': best_revenue,\n",
        "                'purchase_prob': best_prob,\n",
        "                'pulls': self.N_pulls[product_idx, best_price_idx]\n",
        "            }\n",
        "\n",
        "        return best_strategies"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3a6f326",
      "metadata": {
        "id": "e3a6f326"
      },
      "source": [
        "# Theoretical Optimal Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b7f5baa",
      "metadata": {},
      "source": [
        "# Clairvoyant using LSA or Sampling approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a933d584",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def compute_clairvoyant(prices, environment, T, total_inventory, method='sampling'):\n",
        "    \"\"\"\n",
        "    Compute the optimal (clairvoyant) pricing strategy with full information\n",
        "    for the multi-product case with a single shared inventory constraint.\n",
        "\n",
        "    Args:\n",
        "        prices: List of available prices (assumed to be the same for all products)\n",
        "        environment: MultiProductPricingEnvironment to get true demand probabilities\n",
        "        T: Time horizon\n",
        "        total_inventory: Total shared inventory across all products\n",
        "        method: 'sampling' for probabilistic sampling, 'lsa' for Linear Sum Assignment\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with optimal policy information, including per-product insights.\n",
        "    \"\"\"\n",
        "    n_products = environment.n_products\n",
        "    n_price_options = len(prices)\n",
        "    num_vars = n_products * n_price_options\n",
        "\n",
        "    # Compute true demand probabilities for each (product, price) combination\n",
        "    demand_probabilities = np.zeros((n_products, n_price_options))\n",
        "    for product_idx in range(n_products):\n",
        "        for price_idx, price in enumerate(prices):\n",
        "            demand_probabilities[product_idx, price_idx] = 1 - environment.valuation_dists[product_idx].cdf(price)\n",
        "\n",
        "    # Expected revenue per selection for each (product, price) combination\n",
        "    expected_revenues = np.array(prices) * demand_probabilities\n",
        "\n",
        "    # Compute optimal gamma distribution (same for both methods)\n",
        "    gamma_result = compute_optimal_gamma(expected_revenues, demand_probabilities, T, total_inventory)\n",
        "    \n",
        "    if gamma_result is None:\n",
        "        return create_fallback_result(n_products, n_price_options, prices, \n",
        "                                    demand_probabilities, expected_revenues)\n",
        "\n",
        "    gamma = gamma_result['gamma']\n",
        "    lp_optimal_revenue = gamma_result['lp_optimal_revenue']\n",
        "\n",
        "    if method == 'sampling':\n",
        "        return compute_sampling_performance(gamma, prices, expected_revenues, demand_probabilities, \n",
        "                                          lp_optimal_revenue, T, n_products, n_price_options)\n",
        "    elif method == 'lsa':\n",
        "        return compute_lsa_performance(gamma, prices, expected_revenues, demand_probabilities, \n",
        "                                     lp_optimal_revenue, T, n_products, n_price_options)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown method: {method}. Use 'sampling' or 'lsa'\")\n",
        "\n",
        "def compute_optimal_gamma(expected_revenues, demand_probabilities, T, total_inventory):\n",
        "    \"\"\"\n",
        "    Solve the LP to get optimal gamma distribution.\n",
        "    \"\"\"\n",
        "    n_products, n_price_options = expected_revenues.shape\n",
        "    num_vars = n_products * n_price_options\n",
        "\n",
        "    # Set up linear program (convert maximization to minimization)\n",
        "    c = -expected_revenues.flatten()\n",
        "\n",
        "    # Inequality constraints (shared inventory)\n",
        "    A_ub = [demand_probabilities.flatten()]\n",
        "    b_ub = [total_inventory / T]\n",
        "\n",
        "    # Equality constraints (probability distribution for each product)\n",
        "    A_eq = np.zeros((n_products, num_vars))\n",
        "    b_eq = np.ones(n_products)\n",
        "\n",
        "    for product_idx in range(n_products):\n",
        "        start_idx = product_idx * n_price_options\n",
        "        end_idx = start_idx + n_price_options\n",
        "        A_eq[product_idx, start_idx:end_idx] = 1\n",
        "\n",
        "    bounds = [(0, 1) for _ in range(num_vars)]\n",
        "\n",
        "    try:\n",
        "        res = optimize.linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq,\n",
        "                              bounds=bounds, method='highs')\n",
        "\n",
        "        if res.success:\n",
        "            gamma_flat = res.x\n",
        "            gamma = gamma_flat.reshape((n_products, n_price_options))\n",
        "            lp_optimal_revenue = -res.fun * T\n",
        "            \n",
        "            return {\n",
        "                'gamma': gamma,\n",
        "                'lp_optimal_revenue': lp_optimal_revenue\n",
        "            }\n",
        "        else:\n",
        "            print(\"Clairvoyant LP failed to converge.\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Clairvoyant LP Error: {e}\")\n",
        "        return None\n",
        "\n",
        "def compute_sampling_performance(gamma, prices, expected_revenues, demand_probabilities, \n",
        "                               lp_optimal_revenue, T, n_products, n_price_options):\n",
        "    \"\"\"\n",
        "    Compute performance for sampling-based selection (original method).\n",
        "    \"\"\"\n",
        "    optimal_policies = {}\n",
        "    \n",
        "    for product_idx in range(n_products):\n",
        "        best_price_idx_in_dist = np.argmax(gamma[product_idx, :])\n",
        "        optimal_price_for_product = prices[best_price_idx_in_dist]\n",
        "\n",
        "        expected_revenue_per_round_product = np.sum(gamma[product_idx, :] * expected_revenues[product_idx, :])\n",
        "        expected_purchase_prob_product = np.sum(gamma[product_idx, :] * demand_probabilities[product_idx, :])\n",
        "\n",
        "        optimal_policies[product_idx] = {\n",
        "            'optimal_price_distribution': gamma[product_idx, :],\n",
        "            'representative_optimal_price': optimal_price_for_product,\n",
        "            'expected_revenue_per_round': expected_revenue_per_round_product,\n",
        "            'purchase_probability': expected_purchase_prob_product,\n",
        "            'expected_total_revenue_under_dist': expected_revenue_per_round_product * T\n",
        "        }\n",
        "\n",
        "    return {\n",
        "        'method': 'sampling',\n",
        "        'per_product_policies': optimal_policies,\n",
        "        'total_expected_revenue_upper_bound': lp_optimal_revenue,\n",
        "        'optimal_gamma': gamma,\n",
        "        'demand_probabilities': demand_probabilities,\n",
        "        'expected_revenues': expected_revenues\n",
        "    }\n",
        "\n",
        "def compute_lsa_performance(gamma, prices, expected_revenues, demand_probabilities, \n",
        "                          lp_optimal_revenue, T, n_products, n_price_options):\n",
        "    \"\"\"\n",
        "    Compute performance for LSA-based selection.\n",
        "    \n",
        "    LSA selects the deterministic assignment that maximizes gamma-weighted revenues.\n",
        "    \"\"\"\n",
        "    optimal_policies = {}\n",
        "    \n",
        "    # Compute LSA assignment based on gamma-weighted revenues\n",
        "    cost_matrix = -(expected_revenues * gamma)  # Negative for minimization\n",
        "    row_indices, col_indices = linear_sum_assignment(cost_matrix)\n",
        "    \n",
        "    # Calculate actual performance of LSA assignment\n",
        "    lsa_revenue_per_round = 0.0\n",
        "    lsa_purchases_per_round = 0.0\n",
        "    \n",
        "    for product_idx in range(n_products):\n",
        "        selected_price_idx = col_indices[product_idx]\n",
        "        selected_price = prices[selected_price_idx]\n",
        "        \n",
        "        # Revenue and purchase probability for this deterministic choice\n",
        "        revenue_per_round = expected_revenues[product_idx, selected_price_idx]\n",
        "        purchase_prob = demand_probabilities[product_idx, selected_price_idx]\n",
        "        \n",
        "        lsa_revenue_per_round += revenue_per_round\n",
        "        lsa_purchases_per_round += purchase_prob\n",
        "        \n",
        "        optimal_policies[product_idx] = {\n",
        "            'optimal_price_distribution': gamma[product_idx, :],  # Keep original gamma for reference\n",
        "            'lsa_selected_price_idx': selected_price_idx,\n",
        "            'lsa_selected_price': selected_price,\n",
        "            'representative_optimal_price': selected_price,  # For compatibility\n",
        "            'expected_revenue_per_round': revenue_per_round,\n",
        "            'purchase_probability': purchase_prob,\n",
        "            'expected_total_revenue_under_dist': revenue_per_round * T,\n",
        "            'gamma_weight_at_selection': gamma[product_idx, selected_price_idx]\n",
        "        }\n",
        "    \n",
        "    # Check if LSA assignment respects inventory constraint\n",
        "    inventory_constraint_rhs = total_inventory / T  # This needs to be passed as parameter\n",
        "    # Note: We need total_inventory here, but it's not in function signature. \n",
        "    # We'll estimate it from the LP constraint that was binding.\n",
        "    \n",
        "  \n",
        "    effective_rounds = T\n",
        "    \n",
        "    lsa_total_revenue = lsa_revenue_per_round * effective_rounds\n",
        "    \n",
        "    return {\n",
        "        'method': 'lsa',\n",
        "        'per_product_policies': optimal_policies,\n",
        "        'total_expected_revenue_upper_bound': lp_optimal_revenue,  # LP upper bound\n",
        "        'lsa_expected_revenue': lsa_total_revenue,  # Actual LSA performance\n",
        "        'lsa_revenue_per_round': lsa_revenue_per_round,\n",
        "        'lsa_purchases_per_round': lsa_purchases_per_round,\n",
        "        'lsa_assignment': col_indices,\n",
        "        'lsa_effective_rounds': effective_rounds,\n",
        "        'optimal_gamma': gamma,\n",
        "        'demand_probabilities': demand_probabilities,\n",
        "        'expected_revenues': expected_revenues,\n",
        "        'lsa_vs_lp_ratio': lsa_total_revenue / lp_optimal_revenue if lp_optimal_revenue > 0 else 0\n",
        "    }\n",
        "\n",
        "def compute_lsa_performance_with_inventory(gamma, prices, expected_revenues, demand_probabilities, \n",
        "                                         lp_optimal_revenue, T, total_inventory, n_products, n_price_options):\n",
        "    \"\"\"\n",
        "    Enhanced LSA performance calculation with explicit inventory constraint checking.\n",
        "    \"\"\"\n",
        "    # Compute LSA assignment\n",
        "    cost_matrix = -(expected_revenues * gamma)\n",
        "    row_indices, col_indices = linear_sum_assignment(cost_matrix)\n",
        "    \n",
        "    # Calculate LSA performance with inventory constraint\n",
        "    lsa_revenue_per_round = 0.0\n",
        "    lsa_purchases_per_round = 0.0\n",
        "    \n",
        "    optimal_policies = {}\n",
        "    \n",
        "    for product_idx in range(n_products):\n",
        "        selected_price_idx = col_indices[product_idx]\n",
        "        selected_price = prices[selected_price_idx]\n",
        "        \n",
        "        revenue_per_round = expected_revenues[product_idx, selected_price_idx]\n",
        "        purchase_prob = demand_probabilities[product_idx, selected_price_idx]\n",
        "        \n",
        "        lsa_revenue_per_round += revenue_per_round\n",
        "        lsa_purchases_per_round += purchase_prob\n",
        "        \n",
        "        optimal_policies[product_idx] = {\n",
        "            'optimal_price_distribution': gamma[product_idx, :],\n",
        "            'lsa_selected_price_idx': selected_price_idx,\n",
        "            'lsa_selected_price': selected_price,\n",
        "            'representative_optimal_price': selected_price,\n",
        "            'expected_revenue_per_round': revenue_per_round,\n",
        "            'purchase_probability': purchase_prob,\n",
        "            'expected_total_revenue_under_dist': revenue_per_round * T,\n",
        "            'gamma_weight_at_selection': gamma[product_idx, selected_price_idx]\n",
        "        }\n",
        "    \n",
        "    # Check inventory constraint\n",
        "    if lsa_purchases_per_round > 0:\n",
        "        max_rounds_lsa = total_inventory / lsa_purchases_per_round\n",
        "        effective_rounds = min(max_rounds_lsa, T)\n",
        "        inventory_constraint_binding = max_rounds_lsa < T\n",
        "    else:\n",
        "        effective_rounds = T\n",
        "        inventory_constraint_binding = False\n",
        "    \n",
        "    lsa_total_revenue = lsa_revenue_per_round * effective_rounds\n",
        "    \n",
        "    return {\n",
        "        'method': 'lsa',\n",
        "        'per_product_policies': optimal_policies,\n",
        "        'total_expected_revenue_upper_bound': lp_optimal_revenue,\n",
        "        'lsa_expected_revenue': lsa_total_revenue,\n",
        "        'lsa_revenue_per_round': lsa_revenue_per_round,\n",
        "        'lsa_purchases_per_round': lsa_purchases_per_round,\n",
        "        'lsa_assignment': col_indices,\n",
        "        'lsa_effective_rounds': effective_rounds,\n",
        "        'lsa_max_sustainable_rounds': max_rounds_lsa if lsa_purchases_per_round > 0 else T,\n",
        "        'inventory_constraint_binding': inventory_constraint_binding,\n",
        "        'optimal_gamma': gamma,\n",
        "        'demand_probabilities': demand_probabilities,\n",
        "        'expected_revenues': expected_revenues,\n",
        "        'lsa_vs_lp_ratio': lsa_total_revenue / lp_optimal_revenue if lp_optimal_revenue > 0 else 0\n",
        "    }\n",
        "\n",
        "def create_fallback_result(n_products, n_price_options, prices, demand_probabilities, expected_revenues):\n",
        "    \"\"\"Create fallback result when LP fails.\"\"\"\n",
        "    optimal_policies = {}\n",
        "    for product_idx in range(n_products):\n",
        "        optimal_policies[product_idx] = {\n",
        "            'optimal_price_distribution': np.ones(n_price_options) / n_price_options,\n",
        "            'representative_optimal_price': prices[0],\n",
        "            'expected_revenue_per_round': 0.0,\n",
        "            'purchase_probability': 0.0,\n",
        "            'expected_total_revenue_under_dist': 0.0\n",
        "        }\n",
        "    \n",
        "    return {\n",
        "        'per_product_policies': optimal_policies,\n",
        "        'total_expected_revenue_upper_bound': 0.0,\n",
        "        'optimal_gamma': None,\n",
        "        'demand_probabilities': demand_probabilities,\n",
        "        'expected_revenues': expected_revenues\n",
        "    }\n",
        "\n",
        "# Enhanced version that needs to be called separately with total_inventory\n",
        "def compute_clairvoyant_enhanced(prices, environment, T, total_inventory, method='sampling'):\n",
        "    \"\"\"\n",
        "    Enhanced version with proper LSA inventory constraint handling.\n",
        "    \"\"\"\n",
        "    n_products = environment.n_products\n",
        "    n_price_options = len(prices)\n",
        "\n",
        "    # Compute true demand probabilities and expected revenues\n",
        "    demand_probabilities = np.zeros((n_products, n_price_options))\n",
        "    for product_idx in range(n_products):\n",
        "        for price_idx, price in enumerate(prices):\n",
        "            demand_probabilities[product_idx, price_idx] = 1 - environment.valuation_dists[product_idx].cdf(price)\n",
        "\n",
        "    expected_revenues = np.array(prices) * demand_probabilities\n",
        "\n",
        "    # Compute optimal gamma distribution\n",
        "    gamma_result = compute_optimal_gamma(expected_revenues, demand_probabilities, T, total_inventory)\n",
        "    \n",
        "    if gamma_result is None:\n",
        "        return create_fallback_result(n_products, n_price_options, prices, \n",
        "                                    demand_probabilities, expected_revenues)\n",
        "\n",
        "    gamma = gamma_result['gamma']\n",
        "    lp_optimal_revenue = gamma_result['lp_optimal_revenue']\n",
        "\n",
        "    if method == 'sampling':\n",
        "        return compute_sampling_performance(gamma, prices, expected_revenues, demand_probabilities, \n",
        "                                          lp_optimal_revenue, T, n_products, n_price_options)\n",
        "    elif method == 'lsa':\n",
        "        return compute_lsa_performance_with_inventory(gamma, prices, expected_revenues, demand_probabilities, \n",
        "                                                    lp_optimal_revenue, T, total_inventory, n_products, n_price_options)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown method: {method}. Use 'sampling' or 'lsa'\")\n",
        "\n",
        "# Usage examples:\n",
        "\"\"\"\n",
        "# For sampling-based agent (original)\n",
        "clairvoyant_sampling = compute_clairvoyant_enhanced(\n",
        "    prices=your_prices,\n",
        "    environment=your_env,\n",
        "    T=your_T,\n",
        "    total_inventory=your_inventory,\n",
        "    method='sampling'\n",
        ")\n",
        "\n",
        "# For LSA-based agent\n",
        "clairvoyant_lsa = compute_clairvoyant_enhanced(\n",
        "    prices=your_prices,\n",
        "    environment=your_env,\n",
        "    T=your_T,\n",
        "    total_inventory=your_inventory,\n",
        "    method='lsa'\n",
        ")\n",
        "\n",
        "# Compare the two approaches\n",
        "print(f\"LP Upper Bound: {clairvoyant_lsa['total_expected_revenue_upper_bound']:.2f}\")\n",
        "print(f\"LSA Expected: {clairvoyant_lsa['lsa_expected_revenue']:.2f}\")\n",
        "print(f\"LSA vs LP Ratio: {clairvoyant_lsa['lsa_vs_lp_ratio']:.3f}\")\n",
        "print(f\"Inventory Constraint Binding: {clairvoyant_lsa['inventory_constraint_binding']}\")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fdabb3b",
      "metadata": {
        "id": "7fdabb3b"
      },
      "source": [
        "# Simulation and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faf54517",
      "metadata": {
        "id": "faf54517"
      },
      "outputs": [],
      "source": [
        "def run_combinatorial_simulation(environment, agent, T, verbose=True):\n",
        "    \"\"\"\n",
        "    Run a complete simulation of the combinatorial UCB algorithm.\n",
        "\n",
        "    Args:\n",
        "        environment: MultiProductPricingEnvironment instance\n",
        "        agent: CombinatorialUCBWithInventory instance\n",
        "        T: Number of rounds to simulate\n",
        "        verbose: Whether to print progress information\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing simulation results\n",
        "    \"\"\"\n",
        "    total_revenue = 0.0\n",
        "    total_products_sold = 0\n",
        "    revenue_per_round = []\n",
        "    cumulative_revenue = []\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"=== Running Combinatorial UCB Simulation for {T} rounds ===\")\n",
        "        print(f\"Products: {environment.n_products}\")\n",
        "        print(f\"Initial inventory: {agent.initial_inventory}\")\n",
        "        print(f\"Price options: {agent.price_options}\")\n",
        "\n",
        "    for t in range(T):\n",
        "        # Agent selects product subset and prices\n",
        "        product_subset, prices = agent.select_action()\n",
        "\n",
        "        if not product_subset:\n",
        "            # No products available (inventory exhausted)\n",
        "            revenue = 0.0\n",
        "            products_purchased = []\n",
        "        else:\n",
        "            # Convert to price array for environment\n",
        "            price_array = np.zeros(environment.n_products)\n",
        "            for i, product_idx in enumerate(product_subset):\n",
        "                price_array[product_idx] = prices[i]\n",
        "\n",
        "            # Simulate customer interaction\n",
        "            products_purchased, revenue = environment.simulate_round(price_array, product_subset)\n",
        "\n",
        "        # Update agent with outcome\n",
        "        agent.update(products_purchased, revenue)\n",
        "\n",
        "        # Track statistics\n",
        "        total_revenue += revenue\n",
        "        total_products_sold += len(products_purchased)\n",
        "        revenue_per_round.append(revenue)\n",
        "        cumulative_revenue.append(total_revenue)\n",
        "\n",
        "        # Print progress occasionally\n",
        "        if verbose and (t + 1) % (T // 10) == 0:\n",
        "            remaining_inventory = np.sum(agent.remaining_inventory)\n",
        "            print(f\"Round {t + 1:4d}: Revenue = {revenue:6.2f}, \"\n",
        "                  f\"Cumulative = {total_revenue:8.2f}, \"\n",
        "                  f\"Products sold this round = {len(products_purchased)}, \"\n",
        "                  f\"Remaining inventory = {remaining_inventory:.0f}\")\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\n=== Simulation Complete ===\")\n",
        "        print(f\"Total revenue: {total_revenue:.2f}\")\n",
        "        print(f\"Average revenue per round: {total_revenue / T:.2f}\")\n",
        "        print(f\"Total products sold: {total_products_sold}\")\n",
        "        print(f\"Remaining inventory: {agent.remaining_inventory}\")\n",
        "        print(f\"Inventory utilization: {100 * (1 - np.sum(agent.remaining_inventory) / np.sum(agent.initial_inventory)):.1f}%\")\n",
        "\n",
        "    return {\n",
        "        'total_revenue': total_revenue,\n",
        "        'revenue_per_round': revenue_per_round,\n",
        "        'cumulative_revenue': cumulative_revenue,\n",
        "        'total_products_sold': total_products_sold,\n",
        "        'final_inventory': agent.remaining_inventory,\n",
        "        'inventory_utilization': 1 - np.sum(agent.remaining_inventory) / np.sum(agent.initial_inventory),\n",
        "        'agent': agent\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ae51b9e",
      "metadata": {
        "id": "6ae51b9e"
      },
      "source": [
        "# Visualization and Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c7cea31",
      "metadata": {
        "id": "6c7cea31"
      },
      "outputs": [],
      "source": [
        "def plot_combinatorial_results(results, optimal_policy,optimal_total_revenue,  T, environment):\n",
        "    \"\"\"\n",
        "    Generate comprehensive visualizations for combinatorial UCB results.\n",
        "\n",
        "    Args:\n",
        "        results: Simulation results dictionary\n",
        "        optimal_policy: Theoretical optimal policy\n",
        "        T: Number of rounds\n",
        "        environment: Environment instance\n",
        "    \"\"\"\n",
        "    agent = results['agent']\n",
        "    revenue_per_round = results['revenue_per_round']\n",
        "    cumulative_revenue = results['cumulative_revenue']\n",
        "\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
        "\n",
        "    # 1. Cumulative Revenue vs Theoretical Upper Bound\n",
        "    #optimal_upper_bound = optimal_policy['total_expected_revenue_upper_bound']\n",
        "    optimal_upper_bound=optimal_total_revenue\n",
        "\n",
        "\n",
        "    axes[0, 0].plot(cumulative_revenue, label='Combinatorial UCB', linewidth=3, color='blue', alpha=0.8)\n",
        "    axes[0, 0].plot([optimal_upper_bound * (t+1) / T for t in range(T)],\n",
        "                    label='Theoretical Upper Bound', linestyle='--', linewidth=3, color='red', alpha=0.8)\n",
        "\n",
        "    # Performance percentage\n",
        "    final_performance = (\n",
        "        np.mean(\n",
        "        np.array(results['cumulative_revenue']) /\n",
        "        np.array([optimal_upper_bound * (t+1) / T for t in range(T)])\n",
        "    )\n",
        "    ) * 100\n",
        "    axes[0, 0].text(0.02, 0.98, f'Mean Performance: {final_performance:.1f}%\\nof Upper Bound',\n",
        "                    transform=axes[0, 0].transAxes, fontsize=11, va='top',\n",
        "                    bbox=dict(boxstyle=\"round,pad=0.4\", facecolor=\"yellow\", alpha=0.7))\n",
        "\n",
        "    axes[0, 0].set_xlabel('Round')\n",
        "    axes[0, 0].set_ylabel('Cumulative Revenue')\n",
        "    axes[0, 0].set_title('Revenue Performance: Combinatorial UCB vs Upper Bound')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # 2. Revenue per Round (with moving average)\n",
        "    window_size = min(100, T // 20)\n",
        "    if window_size > 1:\n",
        "        moving_avg = np.convolve(revenue_per_round, np.ones(window_size)/window_size, mode='valid')\n",
        "        axes[0, 1].plot(range(window_size-1, T), moving_avg, linewidth=3,\n",
        "                       label=f'Revenue (MA-{window_size})', color='blue', alpha=0.8)\n",
        "    else:\n",
        "        axes[0, 1].plot(revenue_per_round, linewidth=1, alpha=0.7,\n",
        "                       label='Revenue per Round', color='blue')\n",
        "\n",
        "    # Add reference line for average optimal revenue per round\n",
        "    avg_optimal_per_round = optimal_upper_bound / T\n",
        "    axes[0, 1].axhline(avg_optimal_per_round, color='red', linestyle='--', linewidth=2,\n",
        "                       label=f'Avg Optimal ({avg_optimal_per_round:.2f})', alpha=0.8)\n",
        "\n",
        "    axes[0, 1].set_xlabel('Round')\n",
        "    axes[0, 1].set_ylabel('Revenue per Round')\n",
        "    axes[0, 1].set_title('Revenue Convergence Analysis')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    #3. Inventory Levels Over Time\n",
        "    \n",
        "    inventory_history = agent.history['inventory_levels']\n",
        "\n",
        "   \n",
        "    axes[0, 2].plot(inventory_history, linewidth=2, alpha=0.8)\n",
        "\n",
        "    axes[0, 2].set_xlabel('Round')\n",
        "    axes[0, 2].set_ylabel('Remaining Inventory')\n",
        "    axes[0, 2].set_title('Inventory Depletion Over Time')\n",
        "    axes[0, 2].legend()\n",
        "    axes[0, 2].grid(True, alpha=0.3)\n",
        "\n",
        "    # 4. Regret Analysis\n",
        "    # Compute cumulative regret over time\n",
        "    optimal_revenue_per_round = optimal_upper_bound / T\n",
        "    cumulative_optimal = np.array([optimal_revenue_per_round * (t+1) for t in range(T)])\n",
        "    cumulative_regret = cumulative_optimal - np.array(cumulative_revenue)\n",
        "\n",
        "    axes[1, 0].plot(cumulative_regret, linewidth=3, color='red', alpha=0.8, label='Cumulative Regret')\n",
        "\n",
        "    # Add theoretical regret bound\n",
        "    # For bandits with budget constraints: O(√T log T)\n",
        "    t_vals = np.arange(1, T + 1)\n",
        "    theoretical_bound = 2 * np.sqrt(len(agent.price_options) * np.log(t_vals) * t_vals)\n",
        "    axes[1, 0].plot(t_vals, theoretical_bound, '--', color='blue', alpha=0.7, linewidth=2,\n",
        "                   label='Theoretical Bound O(√T log T)')\n",
        "\n",
        "    axes[1, 0].set_xlabel('Round')\n",
        "    axes[1, 0].set_ylabel('Cumulative Regret')\n",
        "    axes[1, 0].set_title('Regret Growth Over Time')\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # 5. Average Regret per Round\n",
        "    avg_regret = cumulative_regret / t_vals\n",
        "\n",
        "    axes[1, 1].plot(avg_regret, linewidth=3, color='purple', alpha=0.8, label='Average Regret')\n",
        "    axes[1, 1].axhline(y=0, color='green', linestyle='--', alpha=0.7, linewidth=2, label='Zero Regret')\n",
        "\n",
        "    # Add moving average for smoother visualization\n",
        "    window = min(500, T // 10)\n",
        "    if window > 1:\n",
        "        moving_avg_regret = np.convolve(avg_regret, np.ones(window)/window, mode='valid')\n",
        "        axes[1, 1].plot(range(window-1, len(avg_regret)), moving_avg_regret,\n",
        "                       linewidth=2, alpha=0.8, color='orange', label=f'Moving Avg ({window})')\n",
        "\n",
        "    axes[1, 1].set_xlabel('Round')\n",
        "    axes[1, 1].set_ylabel('Average Regret per Round')\n",
        "    axes[1, 1].set_title('Average Regret Convergence')\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    # 6. R_T/T Analysis\n",
        "    R_T_over_T = np.array(cumulative_revenue) / (np.arange(1, T + 1))\n",
        "    axes[1, 2].plot(R_T_over_T, linewidth=3, color='orange', alpha=0.8, label='R_T / T')\n",
        "    axes[1, 2].axhline(y=optimal_upper_bound / T, color='red', linestyle='--', linewidth=2,\n",
        "                       label='Optimal Revenue per Round', alpha=0.8)\n",
        "    axes[1, 2].set_xlabel('Round')\n",
        "    axes[1, 2].set_ylabel('R_T / T')\n",
        "    axes[1, 2].set_title('Average Revenue per Round Over Time')\n",
        "    axes[1, 2].legend()\n",
        "    axes[1, 2].grid(True, alpha=0.3)\n",
        "\n",
        "    # Additional Analysis: Best Strategies Summary\n",
        "    print(\"\\n=== Learned Best Strategies per Product ===\")\n",
        "    best_strategies = agent.get_best_strategy()\n",
        "\n",
        "    for product_idx, strategy in best_strategies.items():\n",
        "        opt_info = optimal_policy['per_product_policies'][product_idx]\n",
        "        print(f\"Product {product_idx}:\")\n",
        "        price_dist_str = np.array2string(opt_info['optimal_price_distribution'], precision=2, separator=', ')\n",
        "        print(f\"  Learned best price: {strategy['best_price']:.3f} \"\n",
        "              f\"(Optimal dist: {price_dist_str})\")\n",
        "        print(f\"  Avg revenue: {strategy['avg_revenue']:.3f} \"\n",
        "              f\"(Optimal: {opt_info['expected_revenue_per_round']:.3f})\")\n",
        "        print(f\"  Purchase prob: {strategy['purchase_prob']:.3f} \"\n",
        "              f\"(Optimal: {opt_info['purchase_probability']:.3f})\")\n",
        "        print(f\"  Times tried: {strategy['pulls']:.0f}\")\n",
        "        print()\n",
        "\n",
        "    return {\n",
        "        'final_performance_pct': final_performance,\n",
        "        'inventory_utilization': results['inventory_utilization'],\n",
        "        'best_strategies': best_strategies\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "792f3f03",
      "metadata": {
        "id": "792f3f03"
      },
      "source": [
        "# Experimental Setup and Execution"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fba8e0bf",
      "metadata": {},
      "source": [
        "Select T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab0ce9f0",
      "metadata": {},
      "outputs": [],
      "source": [
        "T=10000"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdbf2b51",
      "metadata": {},
      "source": [
        "# Low budget-> 30% of the total T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d91e7115",
      "metadata": {},
      "outputs": [],
      "source": [
        "inventory_percentage=0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8a29f63",
      "metadata": {},
      "outputs": [],
      "source": [
        "independent=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e572db18",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e572db18",
        "outputId": "e9e1df95-a150-4429-e16c-51762ac055d3"
      },
      "outputs": [],
      "source": [
        "# Experimental Configuration\n",
        "from scipy import stats\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Environment parameters\n",
        "n_products = 3  # Number of different products\n",
        "\n",
        "means = [0.6, 0.4, 0.5]  # Mean valuations for each product\n",
        "std_devs = [0.1, 0.15, 0.08]  # Standard deviations for each product\n",
        "\n",
        "if independent:\n",
        "    # Create independent valuation distributions for each product\n",
        "    valuation_distributions = [\n",
        "        stats.norm(loc=means[0], scale=std_devs[0]),  # Product 0: Higher value, lower variance\n",
        "        stats.norm(loc=means[1], scale=std_devs[1]), # Product 1: Medium value, medium variance\n",
        "        stats.norm(loc=means[2], scale=std_devs[2])  # Product 2: Medium-high value, low variance\n",
        "    ]\n",
        "\n",
        "else:\n",
        "    cov=[[std_devs[0]**2, 0.05, 0.01],\n",
        "        \n",
        "        [0.05, std_devs[1]**2, 0.05],\n",
        "        \n",
        "        [0.01, 0.05, std_devs[2]**2]\n",
        "        ]\n",
        "\n",
        "    valuation_distributions=stats.multivariate_normal(mean=means, cov=cov)\n",
        "\n",
        "\n",
        "if independent:\n",
        "    print(\"\\nProduct valuation distributions:\")\n",
        "    for i, dist in enumerate(valuation_distributions):\n",
        "        print(f\"  Product {i}: Normal(μ={dist.mean():.2f}, σ={dist.std():.3f})\")\n",
        "else:\n",
        "    print(\"\\nProduct valuation distributions:\")\n",
        "    for i in range(len(means)):\n",
        "        print(f\"  Product {i}: Normal(μ={means[i]:.2f}, σ={std_devs[i]:.3f})\")\n",
        "\n",
        "# Inventory constraints per product\n",
        "inventory_per_product = [int(T * 0.1), int(T * 0.05), int(T * 0.15)]  # Different inventory levels\n",
        "inventory=T*inventory_percentage*n_products  # Total inventory across all products\n",
        "\n",
        "\n",
        "# Price options (same for all products for simplicity)\n",
        "epsilon = min(inventory_per_product)**(-1/3)  # Number of price options based on epsilon\n",
        "price_options = np.arange(0.1, 0.9, step=epsilon)  # [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
        "\n",
        "\n",
        "print(\"=== Experimental Setup ===\")\n",
        "print(f\"Number of products: {n_products}\")\n",
        "print(f\"Time horizon: {T} rounds\")\n",
        "print(f\"Price options: {price_options}\")\n",
        "print(f\"Initial inventory: {inventory_per_product}\")\n",
        "print(f\"Total inventory: {sum(inventory_per_product)}\")\n",
        "\n",
        "\n",
        "# Create environment\n",
        "environment = MultiProductPricingEnvironment(valuation_distributions)\n",
        "\n",
        "# Compute theoretical optimal\n",
        "print(\"\\n=== Computing Theoretical Optimal ===\")\n",
        "# optimal_policy = compute_optimal_policy(\n",
        "#     environment, price_options, inventory_per_product, T\n",
        "# )\n",
        "\n",
        "optimal_policy=compute_clairvoyant_enhanced(price_options, environment, T, inventory,method='sampling')\n",
        "optimal_total_revenue=optimal_policy['total_expected_revenue_upper_bound']\n",
        "\n",
        "#optimal_policy=compute_clairvoyant_sampling(price_options, environment, T, inventory, n_samples=1000000)\n",
        "#total_revenue_per_round=optimal_policy['mean_optimal_revenue']\n",
        "\n",
        "\n",
        "# ...existing code...\n",
        "print(\"Optimal single-product policies:\")\n",
        "\n",
        "for product_idx, policy in optimal_policy['per_product_policies'].items():\n",
        "    # Format the price distribution as a string with 2 decimals per value\n",
        "    price_dist_str = np.array2string(policy['optimal_price_distribution'], precision=2, separator=', ')\n",
        "    print(f\"  Product {product_idx}: Price_distribution={price_dist_str}, \"\n",
        "           f\"Revenue/round={policy['expected_revenue_per_round']:.3f}\")\n",
        "\n",
        "print(f\"\\nUpper bound total revenue: {optimal_policy['total_expected_revenue_upper_bound']:.2f}\")\n",
        "print(f\"Upper bound avg revenue/round: {optimal_policy['total_expected_revenue_upper_bound']/T:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2262f84e",
      "metadata": {},
      "source": [
        "# Agent with 'SAMPLING' selection method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40f80541",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40f80541",
        "outputId": "90574f62-2429-4ccd-c255-6c36c4c3bfe3"
      },
      "outputs": [],
      "source": [
        "# Create and run Combinatorial UCB agent_new\n",
        "print(\"\\n=== Creating Combinatorial UCB Agent with LP-based Action Selection ===\")\n",
        "\n",
        "agent_old = CombinatorialUCBWithInventory(\n",
        "    n_products=n_products,\n",
        "    price_options=price_options,\n",
        "    inventory_per_product=inventory_per_product,\n",
        "    T=T,\n",
        "    confidence_bound=1.0,  # UCB confidence parameter\n",
        "    rho_penalty=1.0,       # Penalty factor for inventory constraint\n",
        "    use_pen_rho=True       # Use penalty factor for inventory constraints\n",
        ")\n",
        "\n",
        "agent_new=UCBMatchingAgent(\n",
        "    n_products=n_products,\n",
        "    price_options=price_options,\n",
        "    inventory=inventory,\n",
        "    T=T,\n",
        "    confidence_bound=1,\n",
        "    rho_penalty=1,\n",
        "    use_pen_rho=False,selection_method='sampling')\n",
        "\n",
        "\n",
        "print(f\"Agent initialized with:\")\n",
        "print(f\"  Confidence bound: {agent_new.confidence_bound}\")\n",
        "print(f\"  Rho penalty factor: {agent_new.rho_penalty}\")\n",
        "print(f\"  Use penalty rho: {agent_new.use_pen_rho}\")\n",
        "print(f\"  Products: {agent_new.n_products}\")\n",
        "print(f\"  Price options per product: {len(agent_new.price_options)}\")\n",
        "print(f\"  Total product-price combinations: {agent_new.n_products * len(agent_new.price_options)}\")\n",
        "\n",
        "# Run simulation\n",
        "print(\"\\n=== Running Simulation ===\")\n",
        "results = run_combinatorial_simulation(environment, agent_new, T, verbose=True)\n",
        "\n",
        "# Visualize and analyze results\n",
        "print(\"\\n=== Analyzing Results ===\")\n",
        "\n",
        "analysis_results = plot_combinatorial_results(results, optimal_policy,optimal_total_revenue, T, environment)\n",
        "\n",
        "# Additional detailed analysis\n",
        "print(\"\\n=== Detailed Performance Analysis ===\")\n",
        "\n",
        "# Regret analysis\n",
        "#optimal_total = optimal_policy['total_expected_revenue_upper_bound']\n",
        "optimal_total=optimal_total_revenue\n",
        "actual_total = results['total_revenue']\n",
        "total_regret = optimal_total - actual_total\n",
        "avg_regret_per_round = total_regret / T\n",
        "\n",
        "print(f\"Total regret: {total_regret:.2f}\")\n",
        "print(f\"Average regret per round: {avg_regret_per_round:.4f}\")\n",
        "print(f\"Regret as % of optimal: {100 * total_regret / optimal_total:.2f}%\")\n",
        "\n",
        "# # Inventory analysis\n",
        "# print(f\"\\nInventory utilization by product:\")\n",
        "# for i in range(n_products):\n",
        "#     used = inventory_per_product[i] - results['final_inventory'][i]\n",
        "#     utilization = 100 * used / inventory_per_product[i]\n",
        "#     print(f\"  Product {i}: {used:.0f}/{inventory_per_product[i]} = {utilization:.1f}%\")\n",
        "\n",
        "# Action space exploration\n",
        "unique_actions = set()\n",
        "for action in agent_new.history['actions']:\n",
        "    product_subset, price_indices = action\n",
        "    if product_subset:  # Ignore empty actions\n",
        "        unique_actions.add(tuple(sorted(zip(product_subset, price_indices))))\n",
        "\n",
        "print(f\"\\nExploration statistics:\")\n",
        "print(f\"  Unique actions tried: {len(unique_actions)}\")\n",
        "print(f\"  Total product-price combinations: {n_products * len(price_options)}\")\n",
        "print(f\"  Average actions per round: {len(agent_new.history['actions']) / T:.2f}\")\n",
        "\n",
        "# Revenue distribution analysis\n",
        "revenue_per_round = np.array(results['revenue_per_round'])\n",
        "print(f\"\\nRevenue statistics:\")\n",
        "print(f\"  Mean revenue per round: {np.mean(revenue_per_round):.3f}\")\n",
        "print(f\"  Std revenue per round: {np.std(revenue_per_round):.3f}\")\n",
        "print(f\"  Max revenue in single round: {np.max(revenue_per_round):.3f}\")\n",
        "print(f\"  Rounds with zero revenue: {np.sum(revenue_per_round == 0)} ({100*np.sum(revenue_per_round == 0)/T:.1f}%)\")\n",
        "\n",
        "print(f\"\\n=== Final Summary ===\")\n",
        "print(f\"Combinatorial UCB achieved {analysis_results['final_performance_pct']:.1f}% of theoretical upper bound\")\n",
        "print(f\"Overall inventory utilization: {100*analysis_results['inventory_utilization']:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8a3790b",
      "metadata": {},
      "source": [
        "# Agent with 'LINEAR SUM ASSIGNMENT' selection method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e85a5fb2",
      "metadata": {},
      "outputs": [],
      "source": [
        "optimal_policy=compute_clairvoyant_enhanced(price_options, environment, T, inventory,method='lsa')\n",
        "optimal_total_revenue=optimal_policy['total_expected_revenue_upper_bound']\n",
        "\n",
        "#optimal_policy=compute_clairvoyant_sampling(price_options, environment, T, inventory, n_samples=1000000)\n",
        "#total_revenue_per_round=optimal_policy['mean_optimal_revenue']\n",
        "\n",
        "\n",
        "# ...existing code...\n",
        "print(\"Optimal single-product policies:\")\n",
        "\n",
        "for product_idx, policy in optimal_policy['per_product_policies'].items():\n",
        "    # Format the price distribution as a string with 2 decimals per value\n",
        "    price_dist_str = np.array2string(policy['optimal_price_distribution'], precision=2, separator=', ')\n",
        "    print(f\"  Product {product_idx}: Price_distribution={price_dist_str}, \"\n",
        "           f\"Revenue/round={policy['expected_revenue_per_round']:.3f}\")\n",
        "\n",
        "print(f\"\\nUpper bound total revenue: {optimal_policy['total_expected_revenue_upper_bound']:.2f}\")\n",
        "print(f\"Upper bound avg revenue/round: {optimal_policy['total_expected_revenue_upper_bound']/T:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01029dfa",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create and run Combinatorial UCB agent_new\n",
        "print(\"\\n=== Creating Combinatorial UCB Agent with LP-based Action Selection ===\")\n",
        "\n",
        "agent_old = CombinatorialUCBWithInventory(\n",
        "    n_products=n_products,\n",
        "    price_options=price_options,\n",
        "    inventory_per_product=inventory_per_product,\n",
        "    T=T,\n",
        "    confidence_bound=1.0,  # UCB confidence parameter\n",
        "    rho_penalty=1.0,       # Penalty factor for inventory constraint\n",
        "    use_pen_rho=True       # Use penalty factor for inventory constraints\n",
        ")\n",
        "\n",
        "agent_new=UCBMatchingAgent(\n",
        "    n_products=n_products,\n",
        "    price_options=price_options,\n",
        "    inventory=inventory,\n",
        "    T=T,\n",
        "    confidence_bound=1,\n",
        "    rho_penalty=1,\n",
        "    use_pen_rho=False,selection_method='lsa')\n",
        "\n",
        "\n",
        "print(f\"Agent initialized with:\")\n",
        "print(f\"  Confidence bound: {agent_new.confidence_bound}\")\n",
        "print(f\"  Rho penalty factor: {agent_new.rho_penalty}\")\n",
        "print(f\"  Use penalty rho: {agent_new.use_pen_rho}\")\n",
        "print(f\"  Products: {agent_new.n_products}\")\n",
        "print(f\"  Price options per product: {len(agent_new.price_options)}\")\n",
        "print(f\"  Total product-price combinations: {agent_new.n_products * len(agent_new.price_options)}\")\n",
        "\n",
        "# Run simulation\n",
        "print(\"\\n=== Running Simulation ===\")\n",
        "results = run_combinatorial_simulation(environment, agent_new, T, verbose=True)\n",
        "\n",
        "# Visualize and analyze results\n",
        "print(\"\\n=== Analyzing Results ===\")\n",
        "\n",
        "analysis_results = plot_combinatorial_results(results, optimal_policy,optimal_total_revenue, T, environment)\n",
        "\n",
        "# Additional detailed analysis\n",
        "print(\"\\n=== Detailed Performance Analysis ===\")\n",
        "\n",
        "# Regret analysis\n",
        "#optimal_total = optimal_policy['total_expected_revenue_upper_bound']\n",
        "optimal_total=optimal_total_revenue\n",
        "actual_total = results['total_revenue']\n",
        "total_regret = optimal_total - actual_total\n",
        "avg_regret_per_round = total_regret / T\n",
        "\n",
        "print(f\"Total regret: {total_regret:.2f}\")\n",
        "print(f\"Average regret per round: {avg_regret_per_round:.4f}\")\n",
        "print(f\"Regret as % of optimal: {100 * total_regret / optimal_total:.2f}%\")\n",
        "\n",
        "# # Inventory analysis\n",
        "# print(f\"\\nInventory utilization by product:\")\n",
        "# for i in range(n_products):\n",
        "#     used = inventory_per_product[i] - results['final_inventory'][i]\n",
        "#     utilization = 100 * used / inventory_per_product[i]\n",
        "#     print(f\"  Product {i}: {used:.0f}/{inventory_per_product[i]} = {utilization:.1f}%\")\n",
        "\n",
        "# Action space exploration\n",
        "unique_actions = set()\n",
        "for action in agent_new.history['actions']:\n",
        "    product_subset, price_indices = action\n",
        "    if product_subset:  # Ignore empty actions\n",
        "        unique_actions.add(tuple(sorted(zip(product_subset, price_indices))))\n",
        "\n",
        "print(f\"\\nExploration statistics:\")\n",
        "print(f\"  Unique actions tried: {len(unique_actions)}\")\n",
        "print(f\"  Total product-price combinations: {n_products * len(price_options)}\")\n",
        "print(f\"  Average actions per round: {len(agent_new.history['actions']) / T:.2f}\")\n",
        "\n",
        "# Revenue distribution analysis\n",
        "revenue_per_round = np.array(results['revenue_per_round'])\n",
        "print(f\"\\nRevenue statistics:\")\n",
        "print(f\"  Mean revenue per round: {np.mean(revenue_per_round):.3f}\")\n",
        "print(f\"  Std revenue per round: {np.std(revenue_per_round):.3f}\")\n",
        "print(f\"  Max revenue in single round: {np.max(revenue_per_round):.3f}\")\n",
        "print(f\"  Rounds with zero revenue: {np.sum(revenue_per_round == 0)} ({100*np.sum(revenue_per_round == 0)/T:.1f}%)\")\n",
        "\n",
        "print(f\"\\n=== Final Summary ===\")\n",
        "print(f\"Combinatorial UCB achieved {analysis_results['final_performance_pct']:.1f}% of theoretical upper bound\")\n",
        "print(f\"Overall inventory utilization: {100*analysis_results['inventory_utilization']:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1f81112",
      "metadata": {},
      "source": [
        "# High Budget -> 90% of the total T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e687944",
      "metadata": {},
      "outputs": [],
      "source": [
        "budget=0.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abfd1220",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Experimental Configuration\n",
        "from scipy import stats\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Environment parameters\n",
        "n_products = 3  # Number of different products\n",
        "# Create different valuation distributions for each product\n",
        "valuation_distributions = [\n",
        "    stats.norm(loc=0.6, scale=0.1),  # Product 0: Higher value, lower variance\n",
        "    stats.norm(loc=0.4, scale=0.15), # Product 1: Medium value, medium variance\n",
        "    stats.norm(loc=0.5, scale=0.08)  # Product 2: Medium-high value, low variance\n",
        "]\n",
        "\n",
        "\n",
        "# Inventory constraints per product\n",
        "inventory_per_product = [int(T * 0.1), int(T * 0.05), int(T * 0.15)]  # Different inventory levels\n",
        "inventory=T*budget*n_products  # Total inventory across all products\n",
        "\n",
        "\n",
        "# Price options (same for all products for simplicity)\n",
        "epsilon = min(inventory_per_product)**(-1/3)  # Number of price options based on epsilon\n",
        "price_options = np.arange(0.1, 0.9, step=epsilon)  # [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
        "\n",
        "\n",
        "print(\"=== Experimental Setup ===\")\n",
        "print(f\"Number of products: {n_products}\")\n",
        "print(f\"Time horizon: {T} rounds\")\n",
        "print(f\"Price options: {price_options}\")\n",
        "print(f\"Initial inventory: {inventory_per_product}\")\n",
        "print(f\"Total inventory: {sum(inventory_per_product)}\")\n",
        "\n",
        "# Product valuation info\n",
        "print(\"\\nProduct valuation distributions:\")\n",
        "for i, dist in enumerate(valuation_distributions):\n",
        "    print(f\"  Product {i}: Normal(μ={dist.mean():.2f}, σ={dist.std():.3f})\")\n",
        "\n",
        "# Create environment\n",
        "environment = MultiProductPricingEnvironment(valuation_distributions)\n",
        "\n",
        "# Compute theoretical optimal\n",
        "print(\"\\n=== Computing Theoretical Optimal ===\")\n",
        "# optimal_policy = compute_optimal_policy(\n",
        "#     environment, price_options, inventory_per_product, T\n",
        "# )\n",
        "\n",
        "optimal_policy=compute_clairvoyant_enhanced(price_options, environment, T, inventory,method='sampling')\n",
        "optimal_total_revenue=optimal_policy['total_expected_revenue_upper_bound']\n",
        "\n",
        "#optimal_policy=compute_clairvoyant_sampling(price_options, environment, T, inventory, n_samples=1000000)\n",
        "#total_revenue_per_round=optimal_policy['mean_optimal_revenue']\n",
        "\n",
        "\n",
        "# ...existing code...\n",
        "print(\"Optimal single-product policies:\")\n",
        "\n",
        "for product_idx, policy in optimal_policy['per_product_policies'].items():\n",
        "    # Format the price distribution as a string with 2 decimals per value\n",
        "    price_dist_str = np.array2string(policy['optimal_price_distribution'], precision=2, separator=', ')\n",
        "    print(f\"  Product {product_idx}: Price_distribution={price_dist_str}, \"\n",
        "           f\"Revenue/round={policy['expected_revenue_per_round']:.3f}\")\n",
        "\n",
        "print(f\"\\nUpper bound total revenue: {optimal_policy['total_expected_revenue_upper_bound']:.2f}\")\n",
        "print(f\"Upper bound avg revenue/round: {optimal_policy['total_expected_revenue_upper_bound']/T:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10d189e6",
      "metadata": {},
      "source": [
        "# Agent with 'SAMPLING' selection method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "999d18f2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create and run Combinatorial UCB agent_new\n",
        "print(\"\\n=== Creating Combinatorial UCB Agent with LP-based Action Selection ===\")\n",
        "\n",
        "agent_old = CombinatorialUCBWithInventory(\n",
        "    n_products=n_products,\n",
        "    price_options=price_options,\n",
        "    inventory_per_product=inventory_per_product,\n",
        "    T=T,\n",
        "    confidence_bound=1.0,  # UCB confidence parameter\n",
        "    rho_penalty=1.0,       # Penalty factor for inventory constraint\n",
        "    use_pen_rho=True       # Use penalty factor for inventory constraints\n",
        ")\n",
        "\n",
        "agent_new=UCBMatchingAgent(\n",
        "    n_products=n_products,\n",
        "    price_options=price_options,\n",
        "    inventory=inventory,\n",
        "    T=T,\n",
        "    confidence_bound=1,\n",
        "    rho_penalty=1,\n",
        "    use_pen_rho=False,selection_method='sampling')\n",
        "\n",
        "\n",
        "print(f\"Agent initialized with:\")\n",
        "print(f\"  Confidence bound: {agent_new.confidence_bound}\")\n",
        "print(f\"  Rho penalty factor: {agent_new.rho_penalty}\")\n",
        "print(f\"  Use penalty rho: {agent_new.use_pen_rho}\")\n",
        "print(f\"  Products: {agent_new.n_products}\")\n",
        "print(f\"  Price options per product: {len(agent_new.price_options)}\")\n",
        "print(f\"  Total product-price combinations: {agent_new.n_products * len(agent_new.price_options)}\")\n",
        "\n",
        "# Run simulation\n",
        "print(\"\\n=== Running Simulation ===\")\n",
        "results = run_combinatorial_simulation(environment, agent_new, T, verbose=True)\n",
        "\n",
        "# Visualize and analyze results\n",
        "print(\"\\n=== Analyzing Results ===\")\n",
        "\n",
        "analysis_results = plot_combinatorial_results(results, optimal_policy,optimal_total_revenue, T, environment)\n",
        "\n",
        "# Additional detailed analysis\n",
        "print(\"\\n=== Detailed Performance Analysis ===\")\n",
        "\n",
        "# Regret analysis\n",
        "#optimal_total = optimal_policy['total_expected_revenue_upper_bound']\n",
        "optimal_total=optimal_total_revenue\n",
        "actual_total = results['total_revenue']\n",
        "total_regret = optimal_total - actual_total\n",
        "avg_regret_per_round = total_regret / T\n",
        "\n",
        "print(f\"Total regret: {total_regret:.2f}\")\n",
        "print(f\"Average regret per round: {avg_regret_per_round:.4f}\")\n",
        "print(f\"Regret as % of optimal: {100 * total_regret / optimal_total:.2f}%\")\n",
        "\n",
        "# # Inventory analysis\n",
        "# print(f\"\\nInventory utilization by product:\")\n",
        "# for i in range(n_products):\n",
        "#     used = inventory_per_product[i] - results['final_inventory'][i]\n",
        "#     utilization = 100 * used / inventory_per_product[i]\n",
        "#     print(f\"  Product {i}: {used:.0f}/{inventory_per_product[i]} = {utilization:.1f}%\")\n",
        "\n",
        "# Action space exploration\n",
        "unique_actions = set()\n",
        "for action in agent_new.history['actions']:\n",
        "    product_subset, price_indices = action\n",
        "    if product_subset:  # Ignore empty actions\n",
        "        unique_actions.add(tuple(sorted(zip(product_subset, price_indices))))\n",
        "\n",
        "print(f\"\\nExploration statistics:\")\n",
        "print(f\"  Unique actions tried: {len(unique_actions)}\")\n",
        "print(f\"  Total product-price combinations: {n_products * len(price_options)}\")\n",
        "print(f\"  Average actions per round: {len(agent_new.history['actions']) / T:.2f}\")\n",
        "\n",
        "# Revenue distribution analysis\n",
        "revenue_per_round = np.array(results['revenue_per_round'])\n",
        "print(f\"\\nRevenue statistics:\")\n",
        "print(f\"  Mean revenue per round: {np.mean(revenue_per_round):.3f}\")\n",
        "print(f\"  Std revenue per round: {np.std(revenue_per_round):.3f}\")\n",
        "print(f\"  Max revenue in single round: {np.max(revenue_per_round):.3f}\")\n",
        "print(f\"  Rounds with zero revenue: {np.sum(revenue_per_round == 0)} ({100*np.sum(revenue_per_round == 0)/T:.1f}%)\")\n",
        "\n",
        "print(f\"\\n=== Final Summary ===\")\n",
        "print(f\"Combinatorial UCB achieved {analysis_results['final_performance_pct']:.1f}% of theoretical upper bound\")\n",
        "print(f\"Overall inventory utilization: {100*analysis_results['inventory_utilization']:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7c733ba",
      "metadata": {},
      "source": [
        "# Agent with 'LINEAR SUM ASSIGNMENT' selection method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5df412bd",
      "metadata": {},
      "outputs": [],
      "source": [
        "optimal_policy=compute_clairvoyant_enhanced(price_options, environment, T, inventory,method='lsa')\n",
        "optimal_total_revenue=optimal_policy['total_expected_revenue_upper_bound']\n",
        "\n",
        "#optimal_policy=compute_clairvoyant_sampling(price_options, environment, T, inventory, n_samples=1000000)\n",
        "#total_revenue_per_round=optimal_policy['mean_optimal_revenue']\n",
        "\n",
        "\n",
        "# ...existing code...\n",
        "print(\"Optimal single-product policies:\")\n",
        "\n",
        "for product_idx, policy in optimal_policy['per_product_policies'].items():\n",
        "    # Format the price distribution as a string with 2 decimals per value\n",
        "    price_dist_str = np.array2string(policy['optimal_price_distribution'], precision=2, separator=', ')\n",
        "    print(f\"  Product {product_idx}: Price_distribution={price_dist_str}, \"\n",
        "           f\"Revenue/round={policy['expected_revenue_per_round']:.3f}\")\n",
        "\n",
        "print(f\"\\nUpper bound total revenue: {optimal_policy['total_expected_revenue_upper_bound']:.2f}\")\n",
        "print(f\"Upper bound avg revenue/round: {optimal_policy['total_expected_revenue_upper_bound']/T:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7aa99ee",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create and run Combinatorial UCB agent_new\n",
        "print(\"\\n=== Creating Combinatorial UCB Agent with LP-based Action Selection ===\")\n",
        "\n",
        "agent_old = CombinatorialUCBWithInventory(\n",
        "    n_products=n_products,\n",
        "    price_options=price_options,\n",
        "    inventory_per_product=inventory_per_product,\n",
        "    T=T,\n",
        "    confidence_bound=1.0,  # UCB confidence parameter\n",
        "    rho_penalty=1.0,       # Penalty factor for inventory constraint\n",
        "    use_pen_rho=True       # Use penalty factor for inventory constraints\n",
        ")\n",
        "\n",
        "agent_new=UCBMatchingAgent(\n",
        "    n_products=n_products,\n",
        "    price_options=price_options,\n",
        "    inventory=inventory,\n",
        "    T=T,\n",
        "    confidence_bound=1,\n",
        "    rho_penalty=1,\n",
        "    use_pen_rho=False,selection_method='lsa')\n",
        "\n",
        "\n",
        "print(f\"Agent initialized with:\")\n",
        "print(f\"  Confidence bound: {agent_new.confidence_bound}\")\n",
        "print(f\"  Rho penalty factor: {agent_new.rho_penalty}\")\n",
        "print(f\"  Use penalty rho: {agent_new.use_pen_rho}\")\n",
        "print(f\"  Products: {agent_new.n_products}\")\n",
        "print(f\"  Price options per product: {len(agent_new.price_options)}\")\n",
        "print(f\"  Total product-price combinations: {agent_new.n_products * len(agent_new.price_options)}\")\n",
        "\n",
        "# Run simulation\n",
        "print(\"\\n=== Running Simulation ===\")\n",
        "results = run_combinatorial_simulation(environment, agent_new, T, verbose=True)\n",
        "\n",
        "# Visualize and analyze results\n",
        "print(\"\\n=== Analyzing Results ===\")\n",
        "\n",
        "analysis_results = plot_combinatorial_results(results, optimal_policy,optimal_total_revenue, T, environment)\n",
        "\n",
        "# Additional detailed analysis\n",
        "print(\"\\n=== Detailed Performance Analysis ===\")\n",
        "\n",
        "# Regret analysis\n",
        "#optimal_total = optimal_policy['total_expected_revenue_upper_bound']\n",
        "optimal_total=optimal_total_revenue\n",
        "actual_total = results['total_revenue']\n",
        "total_regret = optimal_total - actual_total\n",
        "avg_regret_per_round = total_regret / T\n",
        "\n",
        "print(f\"Total regret: {total_regret:.2f}\")\n",
        "print(f\"Average regret per round: {avg_regret_per_round:.4f}\")\n",
        "print(f\"Regret as % of optimal: {100 * total_regret / optimal_total:.2f}%\")\n",
        "\n",
        "# # Inventory analysis\n",
        "# print(f\"\\nInventory utilization by product:\")\n",
        "# for i in range(n_products):\n",
        "#     used = inventory_per_product[i] - results['final_inventory'][i]\n",
        "#     utilization = 100 * used / inventory_per_product[i]\n",
        "#     print(f\"  Product {i}: {used:.0f}/{inventory_per_product[i]} = {utilization:.1f}%\")\n",
        "\n",
        "# Action space exploration\n",
        "unique_actions = set()\n",
        "for action in agent_new.history['actions']:\n",
        "    product_subset, price_indices = action\n",
        "    if product_subset:  # Ignore empty actions\n",
        "        unique_actions.add(tuple(sorted(zip(product_subset, price_indices))))\n",
        "\n",
        "print(f\"\\nExploration statistics:\")\n",
        "print(f\"  Unique actions tried: {len(unique_actions)}\")\n",
        "print(f\"  Total product-price combinations: {n_products * len(price_options)}\")\n",
        "print(f\"  Average actions per round: {len(agent_new.history['actions']) / T:.2f}\")\n",
        "\n",
        "# Revenue distribution analysis\n",
        "revenue_per_round = np.array(results['revenue_per_round'])\n",
        "print(f\"\\nRevenue statistics:\")\n",
        "print(f\"  Mean revenue per round: {np.mean(revenue_per_round):.3f}\")\n",
        "print(f\"  Std revenue per round: {np.std(revenue_per_round):.3f}\")\n",
        "print(f\"  Max revenue in single round: {np.max(revenue_per_round):.3f}\")\n",
        "print(f\"  Rounds with zero revenue: {np.sum(revenue_per_round == 0)} ({100*np.sum(revenue_per_round == 0)/T:.1f}%)\")\n",
        "\n",
        "print(f\"\\n=== Final Summary ===\")\n",
        "print(f\"Combinatorial UCB achieved {analysis_results['final_performance_pct']:.1f}% of theoretical upper bound\")\n",
        "print(f\"Overall inventory utilization: {100*analysis_results['inventory_utilization']:.1f}%\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.11.13)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
